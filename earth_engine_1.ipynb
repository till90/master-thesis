{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Engine Communicator \n",
    "API DOC: https://developers.google.com/earth-engine/api_docs#eefeatureget  \n",
    "ReduceRegion https://developers.google.com/earth-engine/reducers_reduce_region  \n",
    "Scale https://developers.google.com/earth-engine/scale  \n",
    "Histogram Matching https://gis.stackexchange.com/questions/332121/histogram-matching-in-google-earth-engine    \n",
    "Determining the sentinel 1 tracks https://gis.stackexchange.com/questions/286922/determining-if-sentinel-1-orbit-is-ascending-or-descending-from-absolute-orbit-n    \n",
    "create sample from feature collection https://mygeoblog.com/2019/04/03/create-sample-from-feature-collection/    \n",
    "Jupter EE map https://github.com/spadarian/jupyter_ee_map  \n",
    "\n",
    "TO-DO: change ReduceRegion function by adding crs and scale, to get   \n",
    "        projection = im.projection().getInfo()['crs']**im.projection().getInfo()['crs']  \n",
    "        im_reduce = im.reduceRegion(reducer = ee.Reducer.mean(),geomery = ried_225_222,crs=projection,scale = 100, maxPixels= 1e9)  \n",
    "  \n",
    "[AOI](#AOI)  \n",
    "[Corine Land Cover](#Corine-Land-Cover-(CLC))\n",
    "[Precipitaion Data](#Precipitaion-Data)  \n",
    "[Soil Moisture](#Soil-Moisture)  \n",
    "[Sentinel1 derives soil-moisture](#Sentinel1-derives-soil-moisture)    \n",
    "[Get CSV for Datasets](#Get-CSV-for-Datasets)  \n",
    "[Data Visualisation](#Data-Visualisation)  \n",
    "[Collection of commands](#Collection-of-commands)  \n",
    "[Collection of Notebook snippets](#Collection-of-Notebook-snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "pip install earthengine-python-api??\n",
    "conda install ipykernel\n",
    "python -m ipykernel install --user\n",
    "conda install -c conda-forge geopandas\n",
    "conda install -c conda-forge ipyleaflet \n",
    "conda install -c conda-forge shapely \n",
    "conda install -c conda-forge scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import datetime\n",
    "import IPython.display\n",
    "from IPython.display import Image\n",
    "import bqplot\n",
    "import ipywidgets\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2) # for printing pretty idk what it is... print with pp.pprint(print stuff)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import dates\n",
    "%matplotlib inline\n",
    "from shapely.geometry import shape\n",
    "import skimage\n",
    "import traitlets\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import ipyleaflet\n",
    "from ipyleaflet import (LayersControl, basemaps, basemap_to_tiles, LayerGroup, Map, Polygon, GeoJSON)\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Connect to Earth Engine API\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOI\n",
    "#ried = ee.FeatureCollection('users/tillmueller1990/ried_roi') Depricated not really Hessisches Ried\n",
    "ried_225_222 = ee.FeatureCollection('users/tillmueller1990/ried_225_222') # Use this but the boundary isn't that precise at borders, got it from wms layer \n",
    "germany = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017').filter(ee.Filter.eq('country_na','Germany'))\n",
    "\n",
    "# Create an empty image into which to paint the features, cast to byte.\n",
    "empty = ee.Image().byte();\n",
    "# Paint all the polygon edges with the same number and width, display.\n",
    "germany_outline = empty.paint(germany, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine Land Cover (CLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last corine land cover image \n",
    "clc = ee.Image.load('COPERNICUS/CORINE/V18_5_1/100m/2012', -1)\n",
    "\n",
    "# Mask areas where soil moisture measurements valid (farmland cat.:11-17)\n",
    "clc_mask = clc.gte(11)and(clc.lte(17)) #binary map for updateMask\n",
    "clc = clc.updateMask(clc_mask) #set mask for not Farmland\n",
    "\n",
    "# Clip to extend of germany\n",
    "clc = clc.clip(germany) \n",
    "\n",
    "# Feature Collection of clc farmland cat.: 11-17 with 350m resolution\n",
    "clc_vector = clc.reduceToVectors(geometry=germany, crs=clc.projection(), scale=350, geometryType='polygon', eightConnected = False)\n",
    "#Limit to first 5000 Features \n",
    "clc_vector = clc_vector.limit(5000)\n",
    "\n",
    "#Sample Points Germany 500\n",
    "random_points = ee.FeatureCollection.randomPoints(clc.geometry(), 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitaion Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Radolan from Assest \n",
    "radolan = ee.ImageCollection('users/tillmueller1990/radolan/r_2009-2019')\n",
    "\n",
    "#Load GSMAP Hourly Precipitation\n",
    "gsmap = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational')\n",
    "\n",
    "#CHIRPS 5km daily precipitation \n",
    "chirps  = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products provided by NASA, ESA, GEE ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASA-USDA Global Soil Moisture Data / 3 days / 2010- 2019 / 0.25 arc degrees / SMOS lvl2 integrated into two-layer palmer model\n",
    "SMOS = ee.ImageCollection('NASA_USDA/HSL/soil_moisture')\n",
    "surface_moisture = SMOS.select('ssm') #units mm, min=0 max=25\n",
    "subsurface_moisture = SMOS.select('susm') #units: mm min=0, max=275\n",
    "moisture_profile = SMOS.select('smp') #units: fraction, min0, max 1\n",
    "\n",
    "#NASA-USDA SMAP Global Soil Moisture Data / 3 days / 2015 - 2019 / 0.25 arc degrees / SMAP level 3 + two-layer Palmer\n",
    "SMAP = ee.ImageCollection('NASA_USDA/HSL/SMAP_soil_moisture')\n",
    "\n",
    "#GLDAS-2.1: Global Land Data Assimilation System / 3 hours / 0.25 arc degrees / 2000 - 2019 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLDAS-2.1: Global Land Data Assimilation System \n",
    "Global Land Data Assimilation System (GLDAS) ingests satellite and ground-based observational data products. Using advanced land surface modeling and data assimilation techniques, it generates optimal fields of land surface states and fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLDAS = ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel1 derives soil-moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentinel 1 backscatter raw data convertet to reflectivity range between 0 and 1 indicator for high reflectivity = high water volume content and vis verse \n",
    "#Load Sentinel 1 and filter data\n",
    "def load_dataset(ImageCollection_ID,begin,end,aoi):\n",
    "    ic = ee.ImageCollection(ImageCollection_ID).filterDate(begin,end).filterBounds(aoi)\n",
    "    return ic\n",
    "\n",
    "def filter_sentinel1(ImageCollection,polarisation,instrumentMode,resolution):\n",
    "    ic = ImageCollection.filter(ee.Filter.listContains('transmitterReceiverPolarisation',polarisation)).filter(ee.Filter.eq('instrumentMode',instrumentMode)).filterMetadata('resolution_meters','equals', resolution)\n",
    "    return ic\n",
    "\n",
    "def seperate_look_angels(ImageCollection):\n",
    "    Ascending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "    Descending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "    return Ascending,Descending\n",
    "\n",
    "def seperate_tiles(ImageCollection,tiles):\n",
    "    tile_list = [x]\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint','transmitterReceiverPolarisation'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[35:43],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def make_mosaic(date,ImageCollection):\n",
    "    date = ee.Date(date['value'])\n",
    "    filterCollection = ImageCollection.filterDate(date, date.advance(1,'day'))\n",
    "    #Make the mosaic\n",
    "    image = ee.Image(filterCollection.mosaic()).copyProperties(filterCollection.first(),[\"system:time_start\"])\n",
    "    #Add the mosaic to a list only if the collection has images\n",
    "    #return ee.List(ee.Algorithms.If(filterCollection.size(), newList.add(image), newList))\n",
    "    return image\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im\n",
    "\n",
    "def add_area(image):\n",
    "    area = image.multiply(ee.Image.pixelArea()).divide(-(1000*1000))\n",
    "    stat = area.reduceRegion(ee.Reducer.sum(),ried_225_222,10) \n",
    "    im = image.set('area',stat.get('VV'))\n",
    "    return im\n",
    "\n",
    "\n",
    "def reproject(image):\n",
    "    VV = image.select('VV')\n",
    "    return image.reporject({crs: VV.projection().crs(), scale : 100})\n",
    "\n",
    "def toNatural(image):\n",
    "    return ee.Image(10.0).pow(imgage.select(0),divide(10.0))\n",
    "\n",
    "def toDB(image):\n",
    "    return ee.Image(image).log10().multiply(10.0)\n",
    "\n",
    "def calc_asc_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_asc.select('VV_max'), 'omegaW' : minMax_asc.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def calc_des_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_des.select('VV_max'), 'omegaW' : minMax_des.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def filter_IC(ImageCollection,filter):\n",
    "    old_size = ImageCollection.size().getInfo()\n",
    "    new_coll = ImageCollection.filter(filter)\n",
    "    new_size = new_coll.size().getInfo()\n",
    "    return new_coll\n",
    "\n",
    "def reducer(ImageCollection,reducer):\n",
    "    im = ImageCollection.reduce(reducer)\n",
    "    return im\n",
    "\n",
    "def plot_image(ImageCollection):\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    ic = GetTileLayerUrl(ImageCollection.first().visualize())\n",
    "    m.add_layer(ic)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "\n",
    "#Time of interest\n",
    "begin = ee.Date.fromYMD(2013,1,1)\n",
    "end = ee.Date.fromYMD(2019,6,1)\n",
    "date_range = end.difference(begin, 'day')\n",
    "\n",
    "#Source dataset\n",
    "sentinel1 = load_dataset('COPERNICUS/S1_GRD',begin,end,ried_225_222)\n",
    "print(\"sentinel1\",type(sentinel1),\"Collection Size: \", sentinel1.size().getInfo())\n",
    "\n",
    "#Filter dataset for High resolution and Vertical transmitt vertical receive\n",
    "sentinel1_VV = filter_sentinel1(sentinel1,'VV','IW',10)\n",
    "print(\"sentinel1_VV\",type(sentinel1_VV),\"Collection Size: \", sentinel1_VV.size().getInfo())\n",
    "\n",
    "#Filter for different look angles\n",
    "VV_Ascending,VV_Descending = seperate_look_angels(sentinel1_VV)\n",
    "print(\"VV_Ascending\",type(VV_Ascending),\"VV_Descending\",type(VV_Descending),\"Collection Size: \", VV_Ascending.size().getInfo(), VV_Descending.size().getInfo())\n",
    "\n",
    "#Clip images to AOI and calculate area property\n",
    "VV_aoi_asc = VV_Ascending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_asc\",type(VV_aoi_asc),\"Collection Size: \", VV_aoi_asc.size().getInfo())\n",
    "VV_aoi_des = VV_Descending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_des\",type(VV_aoi_des),\"Collection Size: \", VV_aoi_des.size().getInfo())\n",
    "\n",
    "#Create Min and Max bands for change detection method\n",
    "minMax_asc = reducer(VV_aoi_asc,ee.Reducer.minMax())\n",
    "print(\"minMax_asc\",type(minMax_asc),minMax_asc.getInfo())\n",
    "minMax_des = reducer(VV_aoi_des,ee.Reducer.minMax())\n",
    "print(\"minMax_des\",type(minMax_des),minMax_des.getInfo())\n",
    "\n",
    "#Compute soil moisture with simple change detection Methode\n",
    "VV_asc_sm = VV_aoi_asc.map(calculate_soilMoisture)\n",
    "print(\"VV_asc_sm\",type(VV_asc_sm),\"Collection Size: \", VV_asc_sm.size().getInfo())\n",
    "VV_des_sm = VV_aoi_des.map(calculate_soilMoisture)\n",
    "print(\"VV_des_sm\",type(VV_des_sm),\"Collection Size: \", VV_des_sm.size().getInfo())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Get list of ids,dates and unique count of prop\n",
    "unique, im_id_list, date_list = get_properties(VV_Ascending)\n",
    "date_list = ee.List([ee.Date(x) for x in date_list])\n",
    "#pp.pprint(unique)\n",
    "\n",
    "#Improve dataset validity \n",
    "VV_aoi_filtered = filter_IC(VV_aoi_area,ee.Filter.gte('area',250))\n",
    "print(\"VV_aoi_filtered\",type(VV_aoi_filtered),\"Collection Size: \", VV_aoi_filtered.size().getInfo())\n",
    "\n",
    "pp.pprint(VV_des_sm.getInfo().get('features')[1])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CSV for Datasets\n",
    "Only year by year otherwise memory exceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV from SMOS soil-moisture for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start,end):\n",
    "    #Geometrys, Regions, Source Dataset, TOI, \n",
    "    start,end = datetime.datetime(2019,1,1),datetime.datetime(2020,1,1)\n",
    "    aoi = ried_225_222\n",
    "    sm = SMOS.filterDate(start,end)\n",
    "\n",
    "    # Function to iterate over image collection, returning a pandas dataframe\n",
    "    def extract_point_values(img_id, aoi):\n",
    "        image = ee.Image(img_id)\n",
    "        #Ad reducer output to the Features in the collection.\n",
    "        fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi, scale=1000)\n",
    "        # Convert to Pandas Dataframe\n",
    "        data_aoi = fc_image_red.getInfo()\n",
    "        data_aoi['geometry'] = aoi.getInfo()['features']\n",
    "        data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['properties']['ID'][23:29],'%y%m%d')\n",
    "        df = pd.DataFrame(data_aoi)\n",
    "        return df\n",
    "\n",
    "    #List of image propertys \n",
    "    im_prop = sm.first().propertyNames().getInfo()\n",
    "    #Get propertie from every image to a List\n",
    "    im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "\n",
    "    #### Create Initial Pandas Dataframe\n",
    "    df_all = extract_point_values(im_id[0], aoi)\n",
    "    df_all = df_all.drop([0])\n",
    "    #### Iterate over all impages\n",
    "    #df_all = pd.DataFrame({})\n",
    "    for i in im_id:\n",
    "        df_all = df_all.append(extract_point_values(i, aoi))\n",
    "    df_all.to_csv(\"SMOS_ried_2019_2020.csv\",index=False)\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for S1 derives Soil Moisture and Backscatter Signal for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id):\n",
    "    IC = VV_asc_sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    im = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    projection = im.projection().getInfo()['crs']**im.projection().getInfo()['crs']\n",
    "    im_reduce = im.reduceRegion(ee.Reducer.mean(),ried_225_222,crs=projection) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    #data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][31:39],'%Y%m%d')\n",
    "    #df = pd.DataFrame(data_aoi,columns=['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg', 'ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg', 'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', 'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst', 'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst', 'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst', 'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst'])\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = VV_asc_sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in VV_asc_sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[33:48],'%Y%m%dT%H%M%S') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"s1_ried_225_222_asc_sm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for Chrisp derived precipitation for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2019,1,1),datetime.datetime(2020,1,1)\n",
    "aoi = ried\n",
    "sm = chirps.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    data_aoi['geometry'] = aoi.getInfo()['features']\n",
    "    data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    df = pd.DataFrame(data_aoi)\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "df_all.to_csv(\"chirps_ried_2019_2020.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for GLDAS climate values for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2010,1,1),datetime.datetime(2010,6,1)\n",
    "aoi = ried\n",
    "sm = GLDAS.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    #data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][31:39],'%Y%m%d')\n",
    "    #df = pd.DataFrame(data_aoi,columns=['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg', 'ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg', 'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', 'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst', 'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst', 'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst', 'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst'])\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[31:44],'%Y%m%d_%H%M') for x in im_id]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"GLDAS_ried_2010_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TileLayerurl from ee to plot on ipyleaflet\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Parameters\n",
    "dark_matter_layer = basemap_to_tiles(basemaps.CartoDB.DarkMatter)\n",
    "germany_viz = GetTileLayerUrl(germany_outline.visualize())\n",
    "#radolan_viz = GetTileLayerUrl(radolan.visualize(min=0,max=40,bands=['b1']))\n",
    "#clc_viz = GetTileLayerUrl(clc.visualize(min=0,max=7,palette=['FFE6FF','FFFFA8','FFFF00','E6E600','E68000','F2A64D','E6A600']))\n",
    "#clc_vector_viz = GetTileLayerUrl(clc_vector.draw(color='red').visualize())\n",
    "#surface_moisture_viz = GetTileLayerUrl(surface_moisture.visualize(min=0,max=28,palette=['0300ff', '418504', 'efff07', 'efff07', 'ff0303']))\n",
    "#random_points_viz = GetTileLayerUrl(random_points.draw(color='blue').visualize())\n",
    "#sentinel1_viz = GetTileLayerUrl(newcol.first().visualize())\n",
    "\n",
    "# Create layer group\n",
    "layer_group = LayerGroup(layers=(#ipyleaflet.TileLayer(url=clc_viz,name='Corine Land Cover 2012')\n",
    "                                 ipyleaflet.TileLayer(url=germany_viz, name='german boundary'),\n",
    "                                 #ipyleaflet.TileLayer(url=clc_vector_viz, name='clc_vector')\n",
    "                                 #ipyleaflet.TileLayer(url=random_points_viz, name='rand point')\n",
    "                                 #ipyleaflet.TileLayer(url=surface_moisture_viz, name='GSMD surface moisture')\n",
    "                                ))\n",
    "#Map options\n",
    "center,zoom = (49.6252978589571, 8.34580993652344),6\n",
    "\n",
    "#Interactive Visualizations\n",
    "map1 = ipyleaflet.Map(layer= dark_matter_layer, center=center, zoom=zoom, layout={'height' : '400px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1.add_layer(layer_group)\n",
    "map1.add_control(LayersControl())\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Coordinates from Drawn Geometry\n",
    "dc.last_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of commands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Command Collection\n",
    ".size().getInfo() # Get collection size\n",
    ".bandNames().getInfo() # Get List with alls Bands from ee.Image not ImageCollection\n",
    ".geometry().bounds().getInfo() # get Geometry of a Feature // Get bounding box of this geometry\n",
    ".limit(5000) # Limit to the first 5000 Elements/Features\n",
    "\n",
    "#Vectorizing\n",
    "var vectors = image.reduceToVectors({\n",
    "  geometry: FeatureCollection,\n",
    "  crs: image.projection(),\n",
    "  scale: 1000,\n",
    "  geometryType: 'polygon',\n",
    "  eightConnected: false,\n",
    "  labelProperty: 'zone',\n",
    "  reducer: ee.Reducer.mean()\n",
    "});\n",
    "\n",
    "#Masking\n",
    ".clip(feature)\n",
    "var image = ee.Image\n",
    "var mask = image.gte(2).and(lt(5))\n",
    "var maskedImage = image.updateMask(mask)\n",
    "\n",
    "#Visualizations\n",
    "thumbnail_url = image.getThumbUrl({\n",
    "    'bands' : '',\n",
    "    'min' : ,\n",
    "    'max' : ,\n",
    "    'region' : .geometry().bounds().getInfo() #must be a geojson \n",
    "})\n",
    "IPython.display.HTML('Thumnail URL: <a href={0}>{0}</a>'.format(thumbnail_url)) #create url to view\n",
    "IPython.display.Image(url=thumbnail_url) # view direct in notebook\n",
    "\n",
    "#Interactive Visualizations\n",
    "import ipyleaflet\n",
    "map1 = ipyleaflet.Map(zoom=3, layout={'height' : '400px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1\n",
    "dc.last_draw # gives information about the last drawn polygon (coordinates etc.)\n",
    "\n",
    "#Function to create a tile layer urlfrom an gee image object\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)\n",
    "\n",
    "#style the image\n",
    "tile_url = GetTileLayerUrl(image.visualize(min=0, max=3000, gamma=1.5, bands=['','','']))\n",
    "map1.add_layer(ipyleaflet.TileLayer(url=tile_url))\n",
    "#or create layer groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Notebook snippets \n",
    "for getting pandas DataFrame of AOI Time Series Satellite Data from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions\n",
    "points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "            ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "            ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "#Time\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2016,1,1)\n",
    "#Source Dataset\n",
    "chirps = chirps_precipitation.filterDate(start,end)\n",
    "# Function Convert a FeatureCollection into a pandas DataFrame; Features is a list of dict with the output\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        #attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #df['geometry'] = map(lambda x: shape(x), df.geometry)    \n",
    "    return df\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, pts):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegions(collection=pts, reducer=ee.Reducer.mean(), scale=1000)\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_red)\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    print(df_image_red)\n",
    "    return df_image_red\n",
    "\n",
    "#List of image propertys \n",
    "chirps_prop = surface_moisture.first().propertyNames().getInfo()\n",
    "print('Check 1')\n",
    "#Get propertie from every image to a List\n",
    "chirps_id = [] #empty list\n",
    "chirps_id = [item.get('id') for item in chirps.getInfo().get('features')]\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(chirps_id[0], points)\n",
    "df_all = df_all.drop([0,1])\n",
    "print(\"check 3\")\n",
    "#### Iterate over all impages\n",
    "c=0\n",
    "for i in chirps_id:\n",
    "    c = c+ 1\n",
    "    print(\"c\",c)\n",
    "    df_all = df_all.append(extract_point_values(i, points))\n",
    "print(\"check 4\")\n",
    "#### Display Results\n",
    "pp.pprint(df_all)\n",
    "rad_point1 = df_all.loc[0]\n",
    "rad_point2 = df_all.loc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import ee\n",
    "from ipygee import *\n",
    "\n",
    "\n",
    "def extract_time_series(start,end,coll,ried): #,sf\n",
    "\n",
    "    \n",
    "    # Obtain image collection for all images within query dates\n",
    "    coll = coll.filterDate(start,end)\n",
    "\n",
    "    # Get list of images which correspond with the above\n",
    "    images = [item.get('id') for item in coll.getInfo().get('features')]\n",
    "    store = []\n",
    "    date_store = []\n",
    "    print(images)\n",
    "    # Loop over all images and extract pixel value\n",
    "    for image in images:\n",
    "        \n",
    "        im = ee.Image(image)\n",
    "        #projection = im.projection().getInfo()['crs']\n",
    "        # Obtain date from timestamp in metadata\n",
    "        date = dt.fromtimestamp(im.get(\"system:time_start\").getInfo() / 1000.)\n",
    "        date_store.append(np.datetime64(date))\n",
    "\n",
    "        # Extract pixel value\n",
    "        data = im.reduceRegion(ee.Reducer.mean(),ried, 1000) #,1, crs=projection).get(band_name) \n",
    "        store.append(data.getInfo())\n",
    "        print(store)\n",
    "    # Scale the returned data based on scale factor\n",
    "    #store = [x * sf if isinstance(x, int) else np.nan for x in store]\n",
    "    \n",
    "    # Convert output into pandas data frame\n",
    "    df = pd.DataFrame(index=date_store, data=store, columns=['precipitation'])\n",
    "    df['store']\n",
    "    return df\n",
    "\n",
    "\n",
    "band_name = 'b1'\n",
    "coll = chirps_precipitation\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2015,1,5)\n",
    "# Set up point geometry\n",
    "points = ee.FeatureCollection([\n",
    "        ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "        ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "        ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "\n",
    "rad_data = extract_time_series(start,end,coll,ried)\n",
    "print(rad_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
