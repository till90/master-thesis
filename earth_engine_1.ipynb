{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table-of-content  \n",
    "\n",
    "[Packages](#Import-Packages)  \n",
    "[AOI](#AOI)  \n",
    "[Indizes](#Indizes)  \n",
    "[Corine Land Cover](#Corine-Land-Cover-(CLC))  \n",
    "[Precipitaion Data](#Precipitaion-Data)  \n",
    "[Soil Moisture](#Soil-Moisture)  \n",
    "[Sentinel1 derives soil-moisture](#Sentinel1-derives-soil-moisture)    \n",
    "[Get CSV for Datasets](#Get-CSV-for-Datasets)  \n",
    "[Data Visualisation](#Data-Visualisation)  \n",
    "[Collection of commands](#Collection-of-commands)  \n",
    "[Collection of Notebook snippets](#Collection-of-Notebook-snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Engine Communicator \n",
    "API DOC: https://developers.google.com/earth-engine/api_docs#eefeatureget  \n",
    "ReduceRegion https://developers.google.com/earth-engine/reducers_reduce_region  \n",
    "Scale https://developers.google.com/earth-engine/scale  \n",
    "Histogram Matching https://gis.stackexchange.com/questions/332121/histogram-matching-in-google-earth-engine    \n",
    "Determining the sentinel 1 tracks https://gis.stackexchange.com/questions/286922/determining-if-sentinel-1-orbit-is-ascending-or-descending-from-absolute-orbit-n    \n",
    "create sample from feature collection https://mygeoblog.com/2019/04/03/create-sample-from-feature-collection/    \n",
    "Jupter EE map https://github.com/spadarian/jupyter_ee_map    \n",
    "Tutorials https://github.com/csaybar/EEwPython\n",
    "TimeSeries and other nice Stuff https://github.com/tylere/PyDataNYC2017/blob/master/ipynb/satellite_analysis.ipynb\n",
    "\n",
    "TO-DO: change ReduceRegion function by adding crs and scale, to get   \n",
    "        projection = im.projection().getInfo()['crs']**im.projection().getInfo()['crs']  \n",
    "        im_reduce = im.reduceRegion(reducer = ee.Reducer.mean(),geometry = ried_225_222,crs=projection,scale = 100, maxPixels= 1e9)    \n",
    "        Tide up import PAckages   \n",
    "        Function Section?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "pip install earthengine-python-api??\n",
    "conda install ipykernel\n",
    "python -m ipykernel install --user\n",
    "conda install -c conda-forge geopandas\n",
    "conda install -c conda-forge ipyleaflet \n",
    "conda install -c conda-forge shapely \n",
    "conda install -c conda-forge scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import ee.mapclient\n",
    "import datetime\n",
    "import IPython.display\n",
    "from IPython.display import Image\n",
    "import bqplot\n",
    "import ipywidgets\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2) # for printing pretty idk what it is... print with pp.pprint(print stuff)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import dates\n",
    "%matplotlib inline\n",
    "from shapely.geometry import shape\n",
    "import skimage\n",
    "import traitlets\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import ipyleaflet\n",
    "from ipyleaflet import (LayersControl, basemaps, basemap_to_tiles, LayerGroup, Map, Polygon, GeoJSON)\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "# Connect to Earth Engine API\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AOI\n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOI\n",
    "ried = ee.FeatureCollection('users/tillmueller1990/ried_roi') #Depricated not really Hessisches Ried\n",
    "ried_225_222 = ee.FeatureCollection('users/tillmueller1990/ried_225_222') # Use this but the boundary isn't that precise at borders, got it from wms layer \n",
    "germany = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017').filter(ee.Filter.eq('country_na','Germany'))\n",
    "\n",
    "# Create an empty image into which to paint the features, cast to byte.\n",
    "empty = ee.Image().byte();\n",
    "# Paint all the polygon edges with the same number and width, display.\n",
    "germany_outline = empty.paint(germany, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets \n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Landsat 8 Surface Reflectance (Atmospheric corrected images)\n",
    "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "\n",
    "#Change Band names to readable bandnames\n",
    "band_names_original = l8sr.first().bandNames()\n",
    "l8_bands = ee.Dictionary({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/gee-community/gee_tools/blob/master/notebooks/cloud_mask/cloud_masking.ipynb  \n",
    "https://mygeoblog.com/2019/01/04/harmonizing-sentinel-2-and-landsat-8/   Mergin s2 und landsat\n",
    "\n",
    "To-Do: Sentinel 2 Cloud mask  \n",
    "maybe merge all together?  \n",
    "Make indize bands  \n",
    "export IC with indize bands as pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5100c815e9db47b1a3b4884d4c5c9aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zoom': 19, 'attribution': 'Map …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f9caf8249f415f908acd2a1e728283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(CustomInspector(children=(SelectMultiple(options=OrderedDict(), value=()), Accordion(selected_in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from geetools import ui, cloud_mask\n",
    "from ipygee import *\n",
    "\n",
    "Map = Map()\n",
    "Map.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "visL8 = {'bands':['B5','B6','B4'],'min':0, 'max':5000}\n",
    "        \n",
    "Map.addLayer(l7toa.first(), visL8, 'Landsat 8 SR Original')\n",
    "Map.centerObject(l7toa, zoom=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "var bandNamesOut = ['blue','green','red','nir','swir1','swir2'];\n",
    "var bandNamesl8 = ['B2','B3','B4','B5','B6','B7'];\n",
    "var bandNamesS2 = ['B2','B3','B4','B8','B11','B12']\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[36:44],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def getQABits(image, start, end, mascara):\n",
    "    # Compute the bits we need to extract.\n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
    "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
    "#A function to mask out cloudy pixels.\n",
    "\n",
    "def maskQuality(image):\n",
    "    # Select the QA band.\n",
    "    QA = image.select('pixel_qa')\n",
    "    # Get the internal_cloud_algorithm_flag bit.\n",
    "    sombra = getQABits(QA,3,3,'cloud_shadow')\n",
    "    nubes = getQABits(QA,5,5,'cloud')\n",
    "    #  var cloud_confidence = getQABits(QA,6,7,  'cloud_confidence')\n",
    "    cirrus_detected = getQABits(QA,9,9,'cirrus_detected')\n",
    "    #var cirrus_detected2 = getQABits(QA,8,8,  'cirrus_detected2')\n",
    "    #Return an image masking out cloudy areas.\n",
    "    return image.updateMask(sombra.eq(0)).updateMask(nubes.eq(0).updateMask(cirrus_detected.eq(0)))\n",
    "\n",
    "def NDVI(image):\n",
    "  \"\"\"A function to compute NDVI.\"\"\"\n",
    "  return image.expression('float(b(\"B4\") - b(\"B3\")) / (b(\"B4\") + b(\"B3\"))')\n",
    "\n",
    "\n",
    "def SAVI(image): #https://de.wikipedia.org/wiki/Soil-Adjusted_Vegetation_Index\n",
    "  \"\"\"A function to compute Soil Adjusted Vegetation Index.\"\"\"\n",
    "  return ee.Image(0).expression(\n",
    "      '(1 + L) * float(nir - red)/ (nir + red + L)',\n",
    "      {\n",
    "          'nir': image.select('B4'),\n",
    "          'red': image.select('B3'),\n",
    "          'L': 0.5\n",
    "      })\n",
    "\n",
    "\n",
    "#unique, im_id_list, date_list = get_properties(l7toa)\n",
    "#print(unique,date_list)\n",
    "#show_tiles(l7toa)\n",
    "\n",
    "# Filter the L7 collection to a single month.\n",
    "l7toa = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR').filterDate(datetime.datetime(2009, 1, 1), datetime.datetime(2019, 6, 1)).filterBounds(ried_225_222).map(maskQuality) #https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LE07_C01_T1_SR\n",
    "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate(datetime.datetime(2009, 1, 1), datetime.datetime(2019, 6, 1)).filterBounds(ried_225_222).map(maskQuality) #https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR\n",
    "s2sr = ee.ImageCollection()\n",
    "\n",
    "Map.addLayer(l8sr.first(), visL8, 'Landsat 8 SR Original')\n",
    "Map.centerObject(l8sr, zoom=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "vis = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': [\n",
    "        'FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163',\n",
    "        '99B718', '74A901', '66A000', '529400', '3E8601',\n",
    "        '207401', '056201', '004C00', '023B01', '012E01',\n",
    "        '011D01', '011301'\n",
    "    ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "main thread is not in main loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2e551dc74951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     ]}\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenterMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m93.7848\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30.3252\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddToMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNDVI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddToMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAVI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\mapclient.py\u001b[0m in \u001b[0;36mcenterMap\u001b[1;34m(lng, lat, zoom)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[0mmap_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMapClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m   \u001b[0mmap_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCenterMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\mapclient.py\u001b[0m in \u001b[0;36mCenterMap\u001b[1;34m(self, lon, lat, opt_zoom)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtktiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2513\u001b[0m         \u001b[1;34m\"\"\"Delete items identified by all tag or ids contained in ARGS.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2514\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delete'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2516\u001b[0m         \"\"\"Delete tag or id given as last arguments in ARGS from items\n",
      "\u001b[1;31mRuntimeError\u001b[0m: main thread is not in main loop"
     ]
    }
   ],
   "source": [
    "# Filter the L7 collection to a single month.\n",
    "collection = (ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA')\n",
    "              .filterDate(datetime.datetime(2002, 11, 1),\n",
    "                          datetime.datetime(2002, 12, 1)))\n",
    "\n",
    "\n",
    "def NDVI(image):\n",
    "  \"\"\"A function to compute NDVI.\"\"\"\n",
    "  return image.expression('float(b(\"B4\") - b(\"B3\")) / (b(\"B4\") + b(\"B3\"))')\n",
    "\n",
    "\n",
    "def SAVI(image):\n",
    "  \"\"\"A function to compute Soil Adjusted Vegetation Index.\"\"\"\n",
    "  return ee.Image(0).expression(\n",
    "      '(1 + L) * float(nir - red)/ (nir + red + L)',\n",
    "      {\n",
    "          'nir': image.select('B4'),\n",
    "          'red': image.select('B3'),\n",
    "          'L': 0.2\n",
    "      })\n",
    "\n",
    "vis = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': [\n",
    "        'FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163',\n",
    "        '99B718', '74A901', '66A000', '529400', '3E8601',\n",
    "        '207401', '056201', '004C00', '023B01', '012E01',\n",
    "        '011D01', '011301'\n",
    "    ]}\n",
    "\n",
    "ee.mapclient.centerMap(-93.7848, 30.3252, 11)\n",
    "ee.mapclient.addToMap(collection.map(NDVI).mean(), vis)\n",
    "ee.mapclient.addToMap(collection.map(SAVI).mean(), vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine Land Cover (CLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last corine land cover image \n",
    "clc = ee.Image.load('COPERNICUS/CORINE/V18_5_1/100m/2012', -1)\n",
    "\n",
    "# Mask areas where soil moisture measurements valid (farmland cat.:11-17)\n",
    "clc_mask = clc.gte(11)and(clc.lte(17)) #binary map for updateMask\n",
    "clc = clc.updateMask(clc_mask) #set mask for not Farmland\n",
    "\n",
    "# Clip to extend of germany\n",
    "clc = clc.clip(ried_225_222) \n",
    "\n",
    "# Feature Collection of clc farmland cat.: 11-17 with 350m resolution\n",
    "clc_vector = clc.reduceToVectors(geometry=germany, crs=clc.projection(), scale=100, geometryType='polygon', eightConnected = False)\n",
    "\n",
    "#im_reduce = im.reduceRegion(reducer = ee.Reducer.mean(),geometry = ried_225_222,crs=projection,scale = 100, maxPixels= 1e9)    \n",
    "#Limit to first 5000 Features \n",
    "#clc_vector = clc_vector.limit(5000)\n",
    "\n",
    "#Sample Points Germany 500\n",
    "random_points = ee.FeatureCollection.randomPoints(clc.geometry(), 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitaion Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Radolan from Assest \n",
    "radolan = ee.ImageCollection('users/tillmueller1990/radolan/r_2009-2019')\n",
    "\n",
    "#Load GSMAP Hourly Precipitation\n",
    "gsmap = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational')\n",
    "\n",
    "#CHIRPS 5km daily precipitation \n",
    "chirps  = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products provided by NASA, ESA, GEE ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASA-USDA Global Soil Moisture Data / 3 days / 2010- 2019 / 0.25 arc degrees / SMOS lvl2 integrated into two-layer palmer model\n",
    "SMOS = ee.ImageCollection('NASA_USDA/HSL/soil_moisture')\n",
    "surface_moisture = SMOS.select('ssm') #units mm, min=0 max=25\n",
    "subsurface_moisture = SMOS.select('susm') #units: mm min=0, max=275\n",
    "moisture_profile = SMOS.select('smp') #units: fraction, min0, max 1\n",
    "\n",
    "#NASA-USDA SMAP Global Soil Moisture Data / 3 days / 2015 - 2019 / 0.25 arc degrees / SMAP level 3 + two-layer Palmer\n",
    "SMAP = ee.ImageCollection('NASA_USDA/HSL/SMAP_soil_moisture')\n",
    "\n",
    "#GLDAS-2.1: Global Land Data Assimilation System / 3 hours / 0.25 arc degrees / 2000 - 2019 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLDAS-2.1: Global Land Data Assimilation System \n",
    "Global Land Data Assimilation System (GLDAS) ingests satellite and ground-based observational data products. Using advanced land surface modeling and data assimilation techniques, it generates optimal fields of land surface states and fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLDAS = ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel1 derives soil-moisture\n",
    "[Table of content](#Table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentinel1 <class 'ee.imagecollection.ImageCollection'> Collection Size:  1160\n",
      "sentinel1_VV <class 'ee.imagecollection.ImageCollection'> Collection Size:  1128\n",
      "VV_Ascending <class 'ee.imagecollection.ImageCollection'> VV_Descending <class 'ee.imagecollection.ImageCollection'> Collection Size:  564 564\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e85403a966b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;31m#Clip images to AOI and calculate area property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0mVV_aoi_asc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVV_Ascending\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_aoi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VV_aoi_asc\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVV_aoi_asc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Collection Size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVV_aoi_asc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[0mVV_aoi_des\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVV_Descending\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_aoi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_area\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VV_aoi_des\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVV_aoi_des\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Collection Size: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVV_aoi_des\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \"\"\"\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0mproject\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         prettyPrint=False))['result']\n\u001b[1;32m--> 665\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msend_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/value'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'json'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json_format'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'v2'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\data.py\u001b[0m in \u001b[0;36msend_\u001b[1;34m(path, params, opt_method, opt_raw)\u001b[0m\n\u001b[0;32m   1690\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m   \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msend_with_backoff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m   \u001b[1;31m# Call the profile hook if present. Note that this is done before we handle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\ee\\data.py\u001b[0m in \u001b[0;36msend_with_backoff\u001b[1;34m(retries)\u001b[0m\n\u001b[0;32m   1681\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m       response, content = http.request(\n\u001b[1;32m-> 1683\u001b[1;33m           url, method=opt_method, body=payload, headers=headers)\n\u001b[0m\u001b[0;32m   1684\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m429\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mMAX_RETRIES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, uri, method, body, headers, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;31m# Make the request.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         response, content = self.http.request(\n\u001b[1;32m--> 198\u001b[1;33m             uri, method, body=body, headers=request_headers, **kwargs)\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;31m# If the response indicated that the credentials needed to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\httplib2\\__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1951\u001b[0m                         \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1952\u001b[0m                         \u001b[0mredirections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1953\u001b[1;33m                         \u001b[0mcachekey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1954\u001b[0m                     )\n\u001b[0;32m   1955\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\httplib2\\__init__.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m         (response, content) = self._conn_request(\n\u001b[1;32m-> 1618\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1619\u001b[0m         )\n\u001b[0;32m   1620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\site-packages\\httplib2\\__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1554\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1556\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1557\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m                 \u001b[1;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\foam\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Sentinel 1 backscatter raw data convertet to reflectivity range between 0 and 1 indicator for high reflectivity = high water volume content and vis verse \n",
    "#Load Sentinel 1 and filter data\n",
    "def load_dataset(ImageCollection_ID,begin,end,aoi):\n",
    "    ic = ee.ImageCollection(ImageCollection_ID).filterDate(begin,end).filterBounds(aoi)\n",
    "    return ic\n",
    "\n",
    "def filter_sentinel1(ImageCollection,polarisation,instrumentMode,resolution):\n",
    "    ic = ImageCollection.filter(ee.Filter.listContains('transmitterReceiverPolarisation',polarisation)).filter(ee.Filter.eq('instrumentMode',instrumentMode)).filterMetadata('resolution_meters','equals', resolution)\n",
    "    return ic\n",
    "\n",
    "def seperate_look_angels(ImageCollection):\n",
    "    Ascending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "    Descending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "    return Ascending,Descending\n",
    "\n",
    "def seperate_tiles(ImageCollection,tiles):\n",
    "    tile_list = [x]\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint','transmitterReceiverPolarisation'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[35:43],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def make_mosaic(date,ImageCollection):\n",
    "    date = ee.Date(date['value'])\n",
    "    filterCollection = ImageCollection.filterDate(date, date.advance(1,'day'))\n",
    "    #Make the mosaic\n",
    "    image = ee.Image(filterCollection.mosaic()).copyProperties(filterCollection.first(),[\"system:time_start\"])\n",
    "    #Add the mosaic to a list only if the collection has images\n",
    "    #return ee.List(ee.Algorithms.If(filterCollection.size(), newList.add(image), newList))\n",
    "    return image\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im\n",
    "\n",
    "def add_area(image):\n",
    "    area = image.multiply(ee.Image.pixelArea()).divide(-(1000*1000))\n",
    "    stat = area.reduceRegion(ee.Reducer.sum(),ried_225_222,10) \n",
    "    im = image.set('area',stat.get('VV'))\n",
    "    return im\n",
    "\n",
    "\n",
    "def reproject(image):\n",
    "    VV = image.select('VV')\n",
    "    return image.reporject({crs: VV.projection().crs(), scale : 100})\n",
    "\n",
    "def toNatural(image):\n",
    "    return ee.Image(10.0).pow(imgage.select(0),divide(10.0))\n",
    "\n",
    "def toDB(image):\n",
    "    return ee.Image(image).log10().multiply(10.0)\n",
    "\n",
    "def calc_asc_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_asc.select('VV_max'), 'omegaW' : minMax_asc.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def calc_des_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_des.select('VV_max'), 'omegaW' : minMax_des.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def filter_IC(ImageCollection,filter):\n",
    "    old_size = ImageCollection.size().getInfo()\n",
    "    new_coll = ImageCollection.filter(filter)\n",
    "    new_size = new_coll.size().getInfo()\n",
    "    return new_coll\n",
    "\n",
    "def reducer(ImageCollection,reducer):\n",
    "    im = ImageCollection.reduce(reducer)\n",
    "    return im\n",
    "\n",
    "def plot_image(ImageCollection):\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    ic = GetTileLayerUrl(ImageCollection.first().visualize())\n",
    "    m.add_layer(ic)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "\n",
    "#Time of interest\n",
    "begin = ee.Date.fromYMD(2013,1,1)\n",
    "end = ee.Date.fromYMD(2019,6,1)\n",
    "date_range = end.difference(begin, 'day')\n",
    "\n",
    "#Source dataset\n",
    "sentinel1 = load_dataset('COPERNICUS/S1_GRD',begin,end,ried_225_222)\n",
    "print(\"sentinel1\",type(sentinel1),\"Collection Size: \", sentinel1.size().getInfo())\n",
    "\n",
    "#Filter dataset for High resolution and Vertical transmitt vertical receive\n",
    "sentinel1_VV = filter_sentinel1(sentinel1,'VV','IW',10)\n",
    "print(\"sentinel1_VV\",type(sentinel1_VV),\"Collection Size: \", sentinel1_VV.size().getInfo())\n",
    "\n",
    "#Filter for different look angles\n",
    "VV_Ascending,VV_Descending = seperate_look_angels(sentinel1_VV)\n",
    "print(\"VV_Ascending\",type(VV_Ascending),\"VV_Descending\",type(VV_Descending),\"Collection Size: \", VV_Ascending.size().getInfo(), VV_Descending.size().getInfo())\n",
    "\n",
    "#Clip images to AOI and calculate area property\n",
    "VV_aoi_asc = VV_Ascending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_asc\",type(VV_aoi_asc),\"Collection Size: \", VV_aoi_asc.size().getInfo())\n",
    "VV_aoi_des = VV_Descending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_des\",type(VV_aoi_des),\"Collection Size: \", VV_aoi_des.size().getInfo())\n",
    "\n",
    "#Create Min and Max bands for change detection method\n",
    "minMax_asc = reducer(VV_aoi_asc,ee.Reducer.minMax())\n",
    "print(\"minMax_asc\",type(minMax_asc),minMax_asc.getInfo())\n",
    "minMax_des = reducer(VV_aoi_des,ee.Reducer.minMax())\n",
    "print(\"minMax_des\",type(minMax_des),minMax_des.getInfo())\n",
    "\n",
    "#Compute soil moisture with simple change detection Methode\n",
    "VV_asc_sm = VV_aoi_asc.map(calculate_soilMoisture)\n",
    "print(\"VV_asc_sm\",type(VV_asc_sm),\"Collection Size: \", VV_asc_sm.size().getInfo())\n",
    "VV_des_sm = VV_aoi_des.map(calculate_soilMoisture)\n",
    "print(\"VV_des_sm\",type(VV_des_sm),\"Collection Size: \", VV_des_sm.size().getInfo())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Get list of ids,dates and unique count of prop\n",
    "unique, im_id_list, date_list = get_properties(VV_Ascending)\n",
    "date_list = ee.List([ee.Date(x) for x in date_list])\n",
    "#pp.pprint(unique)\n",
    "\n",
    "#Improve dataset validity \n",
    "VV_aoi_filtered = filter_IC(VV_aoi_area,ee.Filter.gte('area',250))\n",
    "print(\"VV_aoi_filtered\",type(VV_aoi_filtered),\"Collection Size: \", VV_aoi_filtered.size().getInfo())\n",
    "\n",
    "pp.pprint(VV_des_sm.getInfo().get('features')[1])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CSV for Datasets\n",
    "[Table of content](#Table-of-content)  \n",
    "Only year by year otherwise memory exceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV from SMOS soil-moisture for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start,end):\n",
    "    #Geometrys, Regions, Source Dataset, TOI, \n",
    "    start,end = datetime.datetime(2019,1,1),datetime.datetime(2020,1,1)\n",
    "    aoi = ried_225_222\n",
    "    sm = SMOS.filterDate(start,end)\n",
    "\n",
    "    # Function to iterate over image collection, returning a pandas dataframe\n",
    "    def extract_point_values(img_id, aoi):\n",
    "        image = ee.Image(img_id)\n",
    "        #Ad reducer output to the Features in the collection.\n",
    "        fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi, scale=1000)\n",
    "        # Convert to Pandas Dataframe\n",
    "        data_aoi = fc_image_red.getInfo()\n",
    "        data_aoi['geometry'] = aoi.getInfo()['features']\n",
    "        data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['properties']['ID'][23:29],'%y%m%d')\n",
    "        df = pd.DataFrame(data_aoi)\n",
    "        return df\n",
    "\n",
    "    #List of image propertys \n",
    "    im_prop = sm.first().propertyNames().getInfo()\n",
    "    #Get propertie from every image to a List\n",
    "    im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "\n",
    "    #### Create Initial Pandas Dataframe\n",
    "    df_all = extract_point_values(im_id[0], aoi)\n",
    "    df_all = df_all.drop([0])\n",
    "    #### Iterate over all impages\n",
    "    #df_all = pd.DataFrame({})\n",
    "    for i in im_id:\n",
    "        df_all = df_all.append(extract_point_values(i, aoi))\n",
    "    df_all.to_csv(\"SMOS_ried_2019_2020.csv\",index=False)\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for S1 derives Soil Moisture and Backscatter Signal for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id):\n",
    "    IC = VV_asc_sm.filter(ee.Filter.eq('system:index',img_id))\n",
    "    im = IC.reduce(ee.Reducer.first())\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    projection = im.projection().getInfo()['crs']**im.projection().getInfo()['crs']\n",
    "    im_reduce = im.reduceRegion(ee.Reducer.mean(),ried_225_222,crs=projection) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = im_reduce.getInfo()\n",
    "    #data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][31:39],'%Y%m%d')\n",
    "    #df = pd.DataFrame(data_aoi,columns=['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg', 'ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg', 'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', 'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst', 'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst', 'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst', 'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst'])\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = VV_asc_sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item['properties']['system:index'] for item in VV_asc_sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[33:48],'%Y%m%dT%H%M%S') for x in im_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0])\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"s1_ried_225_222_asc_sm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for Chrisp derived precipitation for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2019,1,1),datetime.datetime(2020,1,1)\n",
    "aoi = ried\n",
    "sm = chirps.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    data_aoi['geometry'] = aoi.getInfo()['features']\n",
    "    data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    df = pd.DataFrame(data_aoi)\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "df_all.to_csv(\"chirps_ried_2019_2020.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV for GLDAS climate values for Ried (1 Polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions, Source Dataset, TOI, \n",
    "start,end = datetime.datetime(2010,1,1),datetime.datetime(2010,6,1)\n",
    "aoi = ried\n",
    "sm = GLDAS.filterDate(start,end)\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, aoi):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegion(ee.Reducer.mean(), aoi) #,scale=1000\n",
    "    # Convert to Pandas Dataframe\n",
    "    data_aoi = fc_image_red.getInfo()\n",
    "    #data_aoi['date'] = datetime.datetime.strptime(image.getInfo()['id'][31:39],'%Y%m%d')\n",
    "    #df = pd.DataFrame(data_aoi,columns=['Albedo_inst', 'AvgSurfT_inst', 'CanopInt_inst', 'ECanop_tavg', 'ESoil_tavg', 'Evap_tavg', 'LWdown_f_tavg', 'Lwnet_tavg', 'PotEvap_tavg', 'Psurf_f_inst', 'Qair_f_inst', 'Qg_tavg', 'Qh_tavg', 'Qle_tavg', 'Qs_acc', 'Qsb_acc', 'Qsm_acc', 'Rainf_f_tavg', 'Rainf_tavg', 'RootMoist_inst', 'SWE_inst', 'SWdown_f_tavg', 'SnowDepth_inst', 'Snowf_tavg', 'SoilMoi0_10cm_inst', 'SoilMoi100_200cm_inst', 'SoilMoi10_40cm_inst', 'SoilMoi40_100cm_inst', 'SoilTMP0_10cm_inst', 'SoilTMP100_200cm_inst', 'SoilTMP10_40cm_inst', 'SoilTMP40_100cm_inst', 'Swnet_tavg', 'Tair_f_inst', 'Tveg_tavg', 'Wind_f_inst'])\n",
    "    df = pd.DataFrame.from_records([data_aoi])\n",
    "    return df\n",
    "\n",
    "#List of image propertys \n",
    "im_prop = sm.first().propertyNames().getInfo()\n",
    "#Get propertie from every image to a List\n",
    "im_id = [item.get('id') for item in sm.getInfo().get('features')]\n",
    "im_date = [datetime.datetime.strptime(x[31:44],'%Y%m%d_%H%M') for x in im_id]\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(im_id[0], aoi)\n",
    "df_all = df_all.drop([0])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in im_id:\n",
    "    df_all = df_all.append(extract_point_values(i, aoi))\n",
    "\n",
    "#Set date and save a lot of .getInfo() calls\n",
    "df_all['date'] = im_date\n",
    "\n",
    "df_all.to_csv(\"GLDAS_ried_2010_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation  \n",
    "[Table of content](#Table-of-content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TileLayerurl from ee to plot on ipyleaflet\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa4c04b51c147c1b416eaaabe9e4fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zoom': 19, 'attribution': 'Map …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization Parameters\n",
    "dark_matter_layer = basemap_to_tiles(basemaps.CartoDB.DarkMatter)\n",
    "germany_viz = GetTileLayerUrl(germany_outline.visualize())\n",
    "#radolan_viz = GetTileLayerUrl(radolan.visualize(min=0,max=40,bands=['b1']))\n",
    "clc_viz = GetTileLayerUrl(clc.visualize(min=0,max=7,palette=['FFE6FF','FFFFA8','FFFF00','E6E600','E68000','F2A64D','E6A600']))\n",
    "#clc_vector_viz = GetTileLayerUrl(clc_vector.draw(color='red').visualize())\n",
    "#surface_moisture_viz = GetTileLayerUrl(surface_moisture.visualize(min=0,max=28,palette=['0300ff', '418504', 'efff07', 'efff07', 'ff0303']))\n",
    "#random_points_viz = GetTileLayerUrl(random_points.draw(color='blue').visualize())\n",
    "#sentinel1_viz = GetTileLayerUrl(newcol.first().visualize())\n",
    "\n",
    "# Create layer group\n",
    "layer_group = LayerGroup(layers=(ipyleaflet.TileLayer(url=clc_viz,name='Corine Land Cover 2012'),\n",
    "                                 ipyleaflet.TileLayer(url=germany_viz, name='german boundary'),\n",
    "                                 #ipyleaflet.TileLayer(url=clc_vector_viz, name='clc_vector')\n",
    "                                 #ipyleaflet.TileLayer(url=random_points_viz, name='rand point')\n",
    "                                 #ipyleaflet.TileLayer(url=surface_moisture_viz, name='GSMD surface moisture')\n",
    "                                ))\n",
    "#Map options\n",
    "center,zoom = (49.6252978589571, 8.34580993652344),11\n",
    "\n",
    "#Interactive Visualizations\n",
    "map1 = ipyleaflet.Map(layer= dark_matter_layer, center=center, zoom=zoom, layout={'height' : '600px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1.add_layer(layer_group)\n",
    "map1.add_control(LayersControl())\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Coordinates from Drawn Geometry\n",
    "dc.last_draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of commands   \n",
    "[Table of content](#table-of-content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Command Collection\n",
    ".size().getInfo() # Get collection size\n",
    ".bandNames().getInfo() # Get List with alls Bands from ee.Image not ImageCollection\n",
    ".geometry().bounds().getInfo() # get Geometry of a Feature // Get bounding box of this geometry\n",
    ".limit(5000) # Limit to the first 5000 Elements/Features\n",
    "\n",
    "#Vectorizing\n",
    "var vectors = image.reduceToVectors({\n",
    "  geometry: FeatureCollection,\n",
    "  crs: image.projection(),\n",
    "  scale: 1000,\n",
    "  geometryType: 'polygon',\n",
    "  eightConnected: false,\n",
    "  labelProperty: 'zone',\n",
    "  reducer: ee.Reducer.mean()\n",
    "});\n",
    "\n",
    "#Masking\n",
    ".clip(feature)\n",
    "var image = ee.Image\n",
    "var mask = image.gte(2).and(lt(5))\n",
    "var maskedImage = image.updateMask(mask)\n",
    "\n",
    "#Visualizations\n",
    "thumbnail_url = image.getThumbUrl({\n",
    "    'bands' : '',\n",
    "    'min' : ,\n",
    "    'max' : ,\n",
    "    'region' : .geometry().bounds().getInfo() #must be a geojson \n",
    "})\n",
    "IPython.display.HTML('Thumnail URL: <a href={0}>{0}</a>'.format(thumbnail_url)) #create url to view\n",
    "IPython.display.Image(url=thumbnail_url) # view direct in notebook\n",
    "\n",
    "#Interactive Visualizations\n",
    "import ipyleaflet\n",
    "map1 = ipyleaflet.Map(zoom=3, layout={'height' : '400px'})\n",
    "dc = ipyleaflet.DrawControl()\n",
    "map1.add_control(dc)\n",
    "map1\n",
    "dc.last_draw # gives information about the last drawn polygon (coordinates etc.)\n",
    "\n",
    "#Function to create a tile layer urlfrom an gee image object\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)\n",
    "\n",
    "#style the image\n",
    "tile_url = GetTileLayerUrl(image.visualize(min=0, max=3000, gamma=1.5, bands=['','','']))\n",
    "map1.add_layer(ipyleaflet.TileLayer(url=tile_url))\n",
    "#or create layer groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection of Notebook snippets \n",
    "[Table of content](#Table-of-content)  \n",
    "for getting pandas DataFrame of AOI Time Series Satellite Data from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geometrys, Regions\n",
    "points = ee.FeatureCollection([\n",
    "            ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "            ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "            ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "#Time\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2016,1,1)\n",
    "#Source Dataset\n",
    "chirps = chirps_precipitation.filterDate(start,end)\n",
    "# Function Convert a FeatureCollection into a pandas DataFrame; Features is a list of dict with the output\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        #attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #df['geometry'] = map(lambda x: shape(x), df.geometry)    \n",
    "    return df\n",
    "\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, pts):\n",
    "    image = ee.Image(img_id)\n",
    "    #Ad reducer output to the Features in the collection.\n",
    "    fc_image_red = image.reduceRegions(collection=pts, reducer=ee.Reducer.mean(), scale=1000)\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_red)\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(image.getInfo()['id'][22:31],'%Y%m%d')\n",
    "    print(df_image_red)\n",
    "    return df_image_red\n",
    "\n",
    "#List of image propertys \n",
    "chirps_prop = surface_moisture.first().propertyNames().getInfo()\n",
    "print('Check 1')\n",
    "#Get propertie from every image to a List\n",
    "chirps_id = [] #empty list\n",
    "chirps_id = [item.get('id') for item in chirps.getInfo().get('features')]\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(chirps_id[0], points)\n",
    "df_all = df_all.drop([0,1])\n",
    "print(\"check 3\")\n",
    "#### Iterate over all impages\n",
    "c=0\n",
    "for i in chirps_id:\n",
    "    c = c+ 1\n",
    "    print(\"c\",c)\n",
    "    df_all = df_all.append(extract_point_values(i, points))\n",
    "print(\"check 4\")\n",
    "#### Display Results\n",
    "pp.pprint(df_all)\n",
    "rad_point1 = df_all.loc[0]\n",
    "rad_point2 = df_all.loc[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://gis.stackexchange.com/questions/313186/extracting-pixel-time-series-from-google-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import ee\n",
    "from ipygee import *\n",
    "\n",
    "\n",
    "def extract_time_series(start,end,coll,ried): #,sf\n",
    "\n",
    "    \n",
    "    # Obtain image collection for all images within query dates\n",
    "    coll = coll.filterDate(start,end)\n",
    "\n",
    "    # Get list of images which correspond with the above\n",
    "    images = [item.get('id') for item in coll.getInfo().get('features')]\n",
    "    store = []\n",
    "    date_store = []\n",
    "    print(images)\n",
    "    # Loop over all images and extract pixel value\n",
    "    for image in images:\n",
    "        \n",
    "        im = ee.Image(image)\n",
    "        #projection = im.projection().getInfo()['crs']\n",
    "        # Obtain date from timestamp in metadata\n",
    "        date = dt.fromtimestamp(im.get(\"system:time_start\").getInfo() / 1000.)\n",
    "        date_store.append(np.datetime64(date))\n",
    "\n",
    "        # Extract pixel value\n",
    "        data = im.reduceRegion(ee.Reducer.mean(),ried, 1000) #,1, crs=projection).get(band_name) \n",
    "        store.append(data.getInfo())\n",
    "        print(store)\n",
    "    # Scale the returned data based on scale factor\n",
    "    #store = [x * sf if isinstance(x, int) else np.nan for x in store]\n",
    "    \n",
    "    # Convert output into pandas data frame\n",
    "    df = pd.DataFrame(index=date_store, data=store, columns=['precipitation'])\n",
    "    df['store']\n",
    "    return df\n",
    "\n",
    "\n",
    "band_name = 'b1'\n",
    "coll = chirps_precipitation\n",
    "start,end = datetime.datetime(2015,1,1),datetime.datetime(2015,1,5)\n",
    "# Set up point geometry\n",
    "points = ee.FeatureCollection([\n",
    "        ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797)),\n",
    "        ee.Feature(ee.Geometry.Point(8.241221721890724,49.6585087644599)),\n",
    "        ])\n",
    "point = ee.Feature(ee.Geometry.Point(8.234870250943459,49.80831604635797))\n",
    "\n",
    "\n",
    "rad_data = extract_time_series(start,end,coll,ried)\n",
    "print(rad_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
