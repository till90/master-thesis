{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installieren des Python Modules radproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorraussetzung ist Python 2 und ArcGIS 64 Bit Extension für Python.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install radproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modul impotieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import radproc as rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die Daten von ftp://ftp-cdc.dwd.de/pub/CDC/grids_germany/hourly/radolan/historical/bin/2018/ in einem Ordner Speichern (ftp_cdc), einen Ordner erstellen wo radproc die entpackten Daten lagern kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW_original = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\ftp_cdc\"\n",
    "RW_unzipped = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\RW_unzipped\"\n",
    "\n",
    "rp.unzip_RW_binaries(zipFolder=RW_original, outFolder=RW_unzipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radproc entpackt nun die Daten in RW_unzipped/Jahr/Monat. Jetzt die Daten impotieren und als HDF5 expotieren, Wenn gewünscht kann eine Shape-Datei als Boundary dienen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create an ID-raster for Germany in ArcGIS, called idras_ger,\n",
    "if you specified a Shapefile or Feature-Class as clipFeature: Clip the german ID-raster to the extent of the clipFeature and create a second ID-raster called idras,\n",
    "import all RADOLAN binary files in a directory tree,\n",
    "select the data for your study area based on the generated ID-raster,\n",
    "convert the selected data into monthly pandas DataFrames and\n",
    "store all DataFrames in the specified HDF5 file.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW_unzipped = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\RW_unzipped\"\n",
    "outHDF = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\aoi.h5\"\n",
    "studyArea = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\boundarys\\aoi_land\\aoi_land.shp\"\n",
    "\n",
    "rp.create_idraster_and_process_radolan_data(inFolder=RW_unzipped,clipFeature=studyArea, HDFFile=outHDF, complevel=9) #clipFeature=studyArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niederschlagssummen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFFile = outHDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lade Daten von HDF5 und Berechne die järhlichen Niederschlagssumen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=0\n",
    "annualSum = rp.hdf5_to_years(\"C:/Users/USER/Desktop/Masterarbeit/DATA/RAD/aoi_land/out_HDF/aoi_land.h5\", 2016)\n",
    "# Display the first five rows of the new DataFrame\n",
    "annualSum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monatliche Niederschlagssumme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = rp.core.load_months_from_hdf5(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi_land\\out_HDF\\aoi_land.h5\",2017)\n",
    "monthlySum = rp.hdf5_to_months(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi_land\\out_HDF\\aoi_land.h5\",2017, 2018)\n",
    "# Display the first five rows of the new DataFrame\n",
    "monthlySum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tägliche Niederschlagssumme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailySum = rp.hdf5_to_days(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\aoi.h5\", year_start=2014, year_end=2018)\n",
    "dailySum.head(2)\n",
    "print(dailySum.index)\n",
    "print(dailySum.columns)\n",
    "\n",
    "#hourlySum = rp.core.hdf5_to_days(HDF, 2016, 2018)\n",
    "#hourlySum.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to ArcGIS Geodatabase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export Jährliche Niederschlagssumme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idRaster = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\idras\"\n",
    "outGDBPath = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\"\n",
    "GDBName = \"aoi_pp_2014_2018.gdb\"\n",
    "statistics = [\"mean\", \"max\",\"min\",\"range\"]\n",
    "\n",
    "rp.export_dfrows_to_gdb(dataDF=hourlySum, idRaster=idRaster, outGDBPath=outGDBPath, GDBName=GDBName, statistics=statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export Monatliche Niederschlagssumme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDBName = \"Months_16_18.gdb\"\n",
    "statistics = [\"mean\", \"max\", \"min\", \"range\"]\n",
    "\n",
    "rp.export_dfrows_to_gdb(dataDF=monthlySum, idRaster=idRaster, outGDBPath=outGDBPath, GDBName=GDBName, statistics=statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Daily PP to GeoDataBase\n",
    "idRaster = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\idras\"\n",
    "outGDBPath = r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\"\n",
    "GDBName = \"aoi_pp_2014_2018.gdb\"\n",
    "statistics = [\"mean\", \"max\",\"min\",\"range\"]\n",
    "\n",
    "rp.export_dfrows_to_gdb(dataDF=hourlySum, idRaster=idRaster, outGDBPath=outGDBPath, GDBName=GDBName, statistics=statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heavy Rainfall Analyse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rp.hdf5_to_days(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\aoi.h5\", year_start=2014, year_end=2018)\n",
    "from datetime import datetime, timedelta, date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#Existing Data\n",
    "index_dates =  pd.date_range(pd.datetime.today(), periods=10).tolist()\n",
    "df = pd.DataFrame({'486335':[0,0,16,0,0,0,2,1,8,2],'486336':[2,1,8,0,11,16,0,1,6,8],'486337':[22,1,22,0,0,0,5,3,6,1]},index=index_dates)\n",
    "columns = df.columns \n",
    "counter_columns = 0\n",
    "print(df.head(5))\n",
    "iteration = -1 #Iterations Steps\n",
    "counter = 10 #10 precipitation values per column\n",
    "duration = 0 #days with no or less than pp_max_1 rain \n",
    "count = False\n",
    "\n",
    "index_list = df.index #Index for updating df / Integear\n",
    "period_range = 0  #Amount of days after Event without much rain Integear\n",
    "period_amount = 0 #Amount of PP in dry days except event Integear\n",
    "event_amount = 0.0  #Amount of heavy rainfall on the event date Float\n",
    "pp = 0 #actual precipitation\n",
    "pp_sum = 0.0 #mm\n",
    "pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "pp_max_1 = 0.11 #max pp for 1 day while counting dry days\n",
    "dry_days = 0 #dry days after event\n",
    "\n",
    "for x in df:\n",
    "    for y in df[x]:\n",
    "        iteration = iteration + 1\n",
    "        if iteration == counter:\n",
    "            iteration = 0\n",
    "            counter_columns = counter_columns + 1\n",
    "            print(\"column :\",counter_columns, \"finished\")\n",
    "        if y >= pp_min and count == False:\n",
    "            duration = duration + 1\n",
    "            count = True\n",
    "            start_period = index_list[iteration]\n",
    "            event_amount = y\n",
    "            index = iteration\n",
    "            pp_sum = pp_sum + y\n",
    "        elif y >= pp_min and count == True or y >= pp_max_1 and count == True:\n",
    "            end_period = index_list[iteration]\n",
    "            dry_periods = dry_periods.append({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount, \"cell\":columns[counter_columns]},ignore_index=True).sort_values('period_range',ascending=False)\n",
    "            duration = 0\n",
    "            count = False\n",
    "            pp_sum = 0\n",
    "        elif pp <= pp_max_1 and count == True:\n",
    "            duration = duration + 1\n",
    "            pp_sum = pp_sum + y\n",
    "        else:\n",
    "            continue\n",
    "print(dry_periods.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2014-01-01', '2014-01-02', '2014-01-03', '2014-01-04',\n",
      "               '2014-01-05', '2014-01-06', '2014-01-07', '2014-01-08',\n",
      "               '2014-01-09', '2014-01-10',\n",
      "               ...\n",
      "               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n",
      "               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n",
      "               '2018-12-30', '2018-12-31'],\n",
      "              dtype='datetime64[ns, UTC]', name=u'Date (UTC)', length=1826, freq='D')\n",
      "DatetimeIndex(['2019-07-04 18:36:24.680000', '2019-07-05 18:36:24.680000',\n",
      "               '2019-07-06 18:36:24.680000', '2019-07-07 18:36:24.680000',\n",
      "               '2019-07-08 18:36:24.680000', '2019-07-09 18:36:24.680000',\n",
      "               '2019-07-10 18:36:24.680000', '2019-07-11 18:36:24.680000',\n",
      "               '2019-07-12 18:36:24.680000', '2019-07-13 18:36:24.680000'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "                           start                       end     amount  \\\n",
      "0      2014-07-08 00:00:00+00:00 2014-07-08 00:00:00+00:00  29.700001   \n",
      "1      2014-07-09 00:00:00+00:00 2014-07-09 00:00:00+00:00  28.300001   \n",
      "2      2014-07-10 00:00:00+00:00 2014-07-11 00:00:00+00:00  19.900000   \n",
      "3      2014-07-29 00:00:00+00:00 2014-07-29 00:00:00+00:00  38.899998   \n",
      "4      2014-08-10 00:00:00+00:00 2014-08-12 00:00:00+00:00  19.900002   \n",
      "5      2014-08-13 00:00:00+00:00 2014-08-13 00:00:00+00:00  21.299999   \n",
      "6      2014-08-26 00:00:00+00:00 2014-08-26 00:00:00+00:00  31.000000   \n",
      "7      2014-09-18 00:00:00+00:00 2014-09-18 00:00:00+00:00  16.600000   \n",
      "8      2014-10-07 00:00:00+00:00 2014-10-07 00:00:00+00:00  15.300000   \n",
      "9      2014-11-04 00:00:00+00:00 2014-11-04 00:00:00+00:00  15.900000   \n",
      "10     2015-04-27 00:00:00+00:00 2015-04-29 00:00:00+00:00  22.299999   \n",
      "11     2015-06-22 00:00:00+00:00 2015-06-22 00:00:00+00:00  18.000000   \n",
      "12     2015-07-04 00:00:00+00:00 2015-07-04 00:00:00+00:00  15.800000   \n",
      "13     2015-08-27 00:00:00+00:00 2015-08-27 00:00:00+00:00  15.300000   \n",
      "14     2015-09-01 00:00:00+00:00 2015-09-02 00:00:00+00:00  21.799999   \n",
      "15     2015-09-16 00:00:00+00:00 2015-09-16 00:00:00+00:00  29.799999   \n",
      "16     2016-03-31 00:00:00+00:00 2016-03-31 00:00:00+00:00  27.400000   \n",
      "17     2016-05-27 00:00:00+00:00 2016-05-27 00:00:00+00:00  30.000000   \n",
      "18     2016-05-29 00:00:00+00:00 2016-05-29 00:00:00+00:00  24.299999   \n",
      "19     2016-05-30 00:00:00+00:00 2016-05-31 00:00:00+00:00  31.400002   \n",
      "20     2016-06-02 00:00:00+00:00 2016-06-02 00:00:00+00:00  24.799999   \n",
      "21     2016-06-05 00:00:00+00:00 2016-06-05 00:00:00+00:00  27.699999   \n",
      "22     2016-06-12 00:00:00+00:00 2016-06-12 00:00:00+00:00  21.500000   \n",
      "23     2016-06-25 00:00:00+00:00 2016-06-25 00:00:00+00:00  19.600000   \n",
      "24     2016-07-23 00:00:00+00:00 2016-07-27 00:00:00+00:00  16.600000   \n",
      "25     2016-08-02 00:00:00+00:00 2016-08-02 00:00:00+00:00  18.000000   \n",
      "26     2017-06-03 00:00:00+00:00 2017-06-03 00:00:00+00:00  15.500000   \n",
      "27     2017-06-22 00:00:00+00:00 2017-06-26 00:00:00+00:00  19.000000   \n",
      "28     2017-07-24 00:00:00+00:00 2017-07-24 00:00:00+00:00  27.100000   \n",
      "29     2017-07-25 00:00:00+00:00 2017-07-25 00:00:00+00:00  24.299999   \n",
      "...                          ...                       ...        ...   \n",
      "672466 2015-08-24 00:00:00+00:00 2015-08-27 00:00:00+00:00  15.700000   \n",
      "672467 2015-11-20 00:00:00+00:00 2015-11-20 00:00:00+00:00  57.900002   \n",
      "672468 2016-02-23 00:00:00+00:00 2016-02-28 00:00:00+00:00  16.100000   \n",
      "672469 2016-04-12 00:00:00+00:00 2016-04-12 00:00:00+00:00  15.700000   \n",
      "672470 2016-04-16 00:00:00+00:00 2016-04-16 00:00:00+00:00  15.700000   \n",
      "672471 2016-05-29 00:00:00+00:00 2016-05-29 00:00:00+00:00  60.299999   \n",
      "672472 2016-05-30 00:00:00+00:00 2016-05-31 00:00:00+00:00  17.500000   \n",
      "672473 2016-06-08 00:00:00+00:00 2016-06-10 00:00:00+00:00  15.200000   \n",
      "672474 2016-06-24 00:00:00+00:00 2016-06-24 00:00:00+00:00  16.200001   \n",
      "672475 2016-07-21 00:00:00+00:00 2016-07-21 00:00:00+00:00  15.500000   \n",
      "672476 2016-07-22 00:00:00+00:00 2016-07-22 00:00:00+00:00  27.600000   \n",
      "672477 2016-08-04 00:00:00+00:00 2016-08-04 00:00:00+00:00  21.900000   \n",
      "672478 2016-10-20 00:00:00+00:00 2016-10-21 00:00:00+00:00  33.900002   \n",
      "672479 2017-05-02 00:00:00+00:00 2017-05-02 00:00:00+00:00  24.200001   \n",
      "672480 2017-05-19 00:00:00+00:00 2017-05-23 00:00:00+00:00  20.100000   \n",
      "672481 2017-06-29 00:00:00+00:00 2017-06-29 00:00:00+00:00  23.000000   \n",
      "672482 2017-07-07 00:00:00+00:00 2017-07-08 00:00:00+00:00  15.800000   \n",
      "672483 2017-07-25 00:00:00+00:00 2017-07-25 00:00:00+00:00  27.700001   \n",
      "672484 2017-09-13 00:00:00+00:00 2017-09-13 00:00:00+00:00  21.400000   \n",
      "672485 2017-09-14 00:00:00+00:00 2017-09-14 00:00:00+00:00  25.400000   \n",
      "672486 2017-10-03 00:00:00+00:00 2017-10-04 00:00:00+00:00  21.400000   \n",
      "672487 2017-11-25 00:00:00+00:00 2017-11-26 00:00:00+00:00  21.100000   \n",
      "672488 2017-12-11 00:00:00+00:00 2017-12-12 00:00:00+00:00  15.400000   \n",
      "672489 2018-01-04 00:00:00+00:00 2018-01-04 00:00:00+00:00  31.299999   \n",
      "672490 2018-05-13 00:00:00+00:00 2018-05-13 00:00:00+00:00  15.100000   \n",
      "672491 2018-06-07 00:00:00+00:00 2018-06-07 00:00:00+00:00  17.700001   \n",
      "672492 2018-08-01 00:00:00+00:00 2018-08-01 00:00:00+00:00  15.500000   \n",
      "672493 2018-09-06 00:00:00+00:00 2018-09-12 00:00:00+00:00  18.100000   \n",
      "672494 2018-12-02 00:00:00+00:00 2018-12-02 00:00:00+00:00  15.100000   \n",
      "672495 2018-12-03 00:00:00+00:00 2018-12-03 00:00:00+00:00  48.599998   \n",
      "\n",
      "        period_range    cell  \n",
      "0                  1  486335  \n",
      "1                  1  486335  \n",
      "2                  2  486335  \n",
      "3                  1  486335  \n",
      "4                  3  486335  \n",
      "5                  1  486335  \n",
      "6                  1  486335  \n",
      "7                  1  486335  \n",
      "8                  1  486335  \n",
      "9                  1  486335  \n",
      "10                 3  486335  \n",
      "11                 1  486335  \n",
      "12                 1  486335  \n",
      "13                 1  486335  \n",
      "14                 2  486335  \n",
      "15                 1  486335  \n",
      "16                 1  486335  \n",
      "17                 1  486335  \n",
      "18                 1  486335  \n",
      "19                 2  486335  \n",
      "20                 1  486335  \n",
      "21                 1  486335  \n",
      "22                 1  486335  \n",
      "23                 1  486335  \n",
      "24                 5  486335  \n",
      "25                 1  486335  \n",
      "26                 1  486335  \n",
      "27                 5  486335  \n",
      "28                 1  486335  \n",
      "29                 1  486335  \n",
      "...              ...     ...  \n",
      "672466             4  589992  \n",
      "672467             1  589992  \n",
      "672468             6  589992  \n",
      "672469             1  589992  \n",
      "672470             1  589992  \n",
      "672471             1  589992  \n",
      "672472             2  589992  \n",
      "672473             3  589992  \n",
      "672474             1  589992  \n",
      "672475             1  589992  \n",
      "672476             1  589992  \n",
      "672477             1  589992  \n",
      "672478             2  589992  \n",
      "672479             1  589992  \n",
      "672480             5  589992  \n",
      "672481             1  589992  \n",
      "672482             2  589992  \n",
      "672483             1  589992  \n",
      "672484             1  589992  \n",
      "672485             1  589992  \n",
      "672486             2  589992  \n",
      "672487             2  589992  \n",
      "672488             2  589992  \n",
      "672489             1  589992  \n",
      "672490             1  589992  \n",
      "672491             1  589992  \n",
      "672492             1  589992  \n",
      "672493             7  589992  \n",
      "672494             1  589992  \n",
      "672495             1  589992  \n",
      "\n",
      "[672496 rows x 5 columns]\n",
      "('processing time: ', 261.61899995803833)\n"
     ]
    }
   ],
   "source": [
    "import radproc as rp\n",
    "from datetime import datetime, timedelta, date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start = time.time()\n",
    "#Existing Data\n",
    "df = rp.hdf5_to_days(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\aoi\\out\\aoi.h5\", year_start=2014, year_end=2018)\n",
    "\n",
    "\n",
    "periods=[]\n",
    "\n",
    "for cell in df.columns:\n",
    "    sub = pd.DataFrame({'amount': df[cell].values}, index=df.index)\n",
    "    sub['flag'] = pd.cut(sub['amount'], [0.11, 15, np.inf],\n",
    "                         labels=[0, 1]).astype(np.float)\n",
    "    sub.loc[sub.flag>0, 'flag']=sub.loc[sub.flag>0, 'flag'].cumsum()\n",
    "    sub.flag.ffill(inplace=True)\n",
    "    x = sub[sub.flag>0].reset_index().groupby('flag').agg(\n",
    "        {'Date (UTC)':['min', 'max'], 'amount': 'sum'})\n",
    "    x.columns = ['start', 'end', 'amount']\n",
    "    x['period_range'] = (x.end - x.start).dt.days + 1\n",
    "    x['cell'] = cell\n",
    "    x.reindex(columns=['start', 'end', 'period_range', 'cell'])\n",
    "    periods.append(x)\n",
    "\n",
    "resul = pd.concat(periods).reset_index(drop=True)\n",
    "\n",
    "print(resul)\n",
    "\n",
    "end = time.time()\n",
    "print(\"processing time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv file\n",
    "resul.to_csv(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\RAD\\analyzed\\dry_periods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new DataFrame for exporting to GDB\n",
    "#new_df = df.pivot(index=dailySum.index, columns='cell')\n",
    "new_df = dailySum.iloc[0:0]\n",
    "index_df = dailySum.index\n",
    "bla = pd.concat([new_df,index_df],axis=0)\n",
    "print(bla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#print(dailySum.head(5))\n",
    "#DataFrame \n",
    "dry_periods = pd.DataFrame(columns=(\"start_period\",\"end_period\",\"period_range\",\"period_amount\",\"event_amount\"))\n",
    "dry_periods.start_period = dry_periods.start_period.astype('datetime64[ns]')\n",
    "dry_periods.end_period = dry_periods.end_period.astype('datetime64[ns]')\n",
    "#dry_periods.period_range = dry_periods.period_range.astype('int64')\n",
    "#dry_periods.period_amount = dry_periods.period_amount.astype('float64')\n",
    "#dry_periods.event_amount = dry_periods.event_amount.astype('float64')\n",
    "\n",
    "#print(dry_periods.dtypes)\n",
    "#dry_periods = dry_periods(start_period, dtype='datetime64[ns]')\n",
    "#print(dry_periods.head(5))\n",
    "#new_entry = pd.DataFrame({\"start_period\":datetime.date.today() ,\"end_period\":datetime.date.today() + timedelta(days=1),\"period_range\": 10,\"period_amount\": 1,\"event_amount\":12},index=[1])\n",
    "#dry_periods.update(new_entry)\n",
    "#print(dry_periods.head(5))\n",
    "columns = dailySum.columns\n",
    "print(len(columns))\n",
    "numbers = range(len(columns))\n",
    "d = dict(zip(numbers,columns))\n",
    "#print(d)\n",
    "#dailySum.round(2)\n",
    "#print(d)\n",
    "\n",
    "#Variables \n",
    "index_list = dailySum.index #Index for updating df / Integear\n",
    "#print(type(index_list),index_list)\n",
    "#start_period = datetime.date.today() #Datetime object. Event Date of heavy rainfall\n",
    "#end_period = datetime.date.today()  #Datetime object. End of dry period after Event\n",
    "period_range = 0  #Amount of days after Event without much rain Integear\n",
    "period_amount = 0 #Amount of PP in dry days except event Integear\n",
    "event_amount = 0.0  #Amount of heavy rainfall on the event date Float\n",
    "#print(dailySum)\n",
    "#Conditions\n",
    "iteration = -1 #Iterations Steps\n",
    "duration = 0 #days\n",
    "duration_min_bevor = 4 #min dry days bevore survey start #necessary????\n",
    "duration_min_after = 10 #min dry days after survey\n",
    "pp = 0 #current pp\n",
    "pp_sum = 0.0 #mm\n",
    "pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "pp_max_1 = 0.11 #max pp for 1 day while counting dry days\n",
    "pp_max_2 = 0.5 #max pp for 1 week while counting dry days\n",
    "dry_days = 0 #dry days after event\n",
    "row = -1 #Panda rows\n",
    "count = False\n",
    "\n",
    "for x in dailySum[columns[0]]:\n",
    "    iteration = iteration + 1\n",
    "    if x >= pp_min and count == False:\n",
    "        duration = duration + 1\n",
    "        count = True\n",
    "        row = row + 1\n",
    "        start_period = index_list[iteration]\n",
    "        event_amount = x\n",
    "        index = iteration\n",
    "        pp_sum = pp_sum + x\n",
    "        continue\n",
    "    elif x >= pp_min and count == True or x >= pp_max_1 and count == True:\n",
    "        end_period = index_list[iteration]\n",
    "        #new_entry = pd.DataFrame({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount} ,index=[1])\n",
    "        #dry_periods.update(new_entry)\n",
    "        dry_periods = dry_periods.append({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount},ignore_index=True)\n",
    "        duration = 0\n",
    "        count = False\n",
    "        pp_sum = 0\n",
    "    elif pp <= pp_max_1 and count == True:\n",
    "        duration = duration + 1\n",
    "        pp_sum = pp_sum + x\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#print(dry_periods)\n",
    "dictt = {}\n",
    "def test():\n",
    "    index_list = dailySum.index #Index for updating df / Integear\n",
    "    period_range = 0  #Amount of days after Event without much rain Integear\n",
    "    period_amount = 0 #Amount of PP in dry days except event Integear\n",
    "    event_amount = 0.0  #Amount of heavy rainfall on the event date Float\n",
    "    iteration = -1 #Iterations Steps\n",
    "    duration = 0 #days\n",
    "    duration_min_bevor = 4 #min dry days bevore survey start #necessary????\n",
    "    duration_min_after = 10 #min dry days after survey\n",
    "    pp = 0 #current pp\n",
    "    pp_sum = 0.0 #mm\n",
    "    pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "    pp_max_1 = 0.11 #max pp for 1 day while counting dry days\n",
    "    pp_max_2 = 0.5 #max pp for 1 week while counting dry days\n",
    "    dry_days = 0 #dry days after event\n",
    "    row = -1 #Panda rows\n",
    "    count = False\n",
    "    dry_periods = pd.DataFrame(columns=(\"start_period\",\"end_period\",\"period_range\",\"period_amount\",\"event_amount\",\"cell\"))\n",
    "    dry_periods.start_period = dry_periods.start_period.astype('datetime64[ns]')\n",
    "    dry_periods.end_period = dry_periods.end_period.astype('datetime64[ns]')\n",
    "    columns = dailySum.columns\n",
    "    numbers = range(len(columns))\n",
    "    d = dict(zip(numbers,columns))\n",
    "    counter = 1826 #4 normal 1 schaltjahr (366)\n",
    "    counter_columns = 0\n",
    "    #dailySum1 = dailySum.iloc[0:0]\n",
    "    for column in dailySum:\n",
    "        for x in dailySum[columns]:\n",
    "            iteration = iteration + 1\n",
    "            print(iteration)\n",
    "            if iteration == counter:\n",
    "                iteration = 0\n",
    "                counter_columns = counter_columns + 1\n",
    "                print(\"Year :\",counter_columns, \"finished\")\n",
    "            if x >= pp_min and count == False:\n",
    "                duration = duration + 1\n",
    "                count = True\n",
    "                row = row + 1\n",
    "                start_period = index_list[iteration]\n",
    "                event_amount = x\n",
    "                index = iteration\n",
    "                pp_sum = pp_sum + x\n",
    "                continue\n",
    "            elif x >= pp_min and count == True or x >= pp_max_1 and count == True:\n",
    "                end_period = index_list[iteration]\n",
    "                #new_entry = pd.DataFrame({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount} ,index=[1])\n",
    "                #dry_periods.update(new_entry)\n",
    "                dry_periods = dry_periods.append({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount, \"cell\":columns[counter_columns]},ignore_index=True).sort_values('period_range',ascending=False)\n",
    "                duration = 0\n",
    "                count = False\n",
    "                pp_sum = 0\n",
    "            elif pp <= pp_max_1 and count == True:\n",
    "                duration = duration + 1\n",
    "                pp_sum = pp_sum + x\n",
    "            else:\n",
    "                continue\n",
    "         #return dictt.update({dry_periods.iat[0,4]:{\"start_period\":dry_periods[\"start_period\"] ,\"end_period\":dry_periods[\"end_period\"],\"period_range\":dry_periods[\"period_range\"],\"period_amount\":dry_periods[\"period_amount\"] ,\"event_amount\":dry_periods[\"event_amount\"]}})\n",
    "    return dry_periods #.to_dict(orient='dict')\n",
    "\n",
    "finish = test()\n",
    "print(finish.head(10))\n",
    "print(\"finished\")\n",
    "#print(test())\n",
    "#print(\"asdasda\",test(1).iloc[0][\"start_period\"])\n",
    "#dailySum1 = dailySum.iloc[0:0]    \n",
    "#print(test(1).iloc[0:3,0],test(1).iloc[0:3,5])\n",
    "#print(test(100).iloc[0:3,0])\n",
    "#dailySum1.iat[0,0] = test(0).iloc[0:5]\n",
    "#dailySum1.486335 = dry_periods.486335.astype('datetime64[ns]')\n",
    "#dailySum1 = dailySum1.append(test(0).iloc[0][\"start_period\"])\n",
    "#print(dailySum1)\n",
    "\n",
    "#columns = dailySum1.columns\n",
    "#for x in range(10):\n",
    "#    dailySum1.iat[0,0] = test(x)\n",
    "#print(\"asdasdad\",dailySum1.iat[0,0])\n",
    "#dailySum1.iat[0,0] = dry_periods.iat[0,0]\n",
    "#raster1 = test(0)\n",
    "#raster2 = test(1)\n",
    "#print(dailySum1)\n",
    "#df = pd.DataFrame(columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dailySum.head(10)\n",
    "print((df.index))\n",
    "\n",
    "for column in df:\n",
    "    for row in df[column]:\n",
    "        print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#print(dailySum.head(5))\n",
    "#DataFrame \n",
    "dry_periods = pd.DataFrame(columns=(\"start_period\",\"end_period\",\"period_range\",\"period_amount\",\"event_amount\"))\n",
    "dry_periods.start_period = dry_periods.start_period.astype('datetime64[ns]')\n",
    "dry_periods.end_period = dry_periods.end_period.astype('datetime64[ns]')\n",
    "#dry_periods.period_range = dry_periods.period_range.astype('int64')\n",
    "#dry_periods.period_amount = dry_periods.period_amount.astype('float64')\n",
    "#dry_periods.event_amount = dry_periods.event_amount.astype('float64')\n",
    "\n",
    "#print(dry_periods.dtypes)\n",
    "#dry_periods = dry_periods(start_period, dtype='datetime64[ns]')\n",
    "#print(dry_periods.head(5))\n",
    "#new_entry = pd.DataFrame({\"start_period\":datetime.date.today() ,\"end_period\":datetime.date.today() + timedelta(days=1),\"period_range\": 10,\"period_amount\": 1,\"event_amount\":12},index=[1])\n",
    "#dry_periods.update(new_entry)\n",
    "#print(dry_periods.head(5))\n",
    "columns = dailySum.columns\n",
    "print(len(columns))\n",
    "numbers = range(len(columns))\n",
    "d = dict(zip(numbers,columns))\n",
    "#print(d)\n",
    "#dailySum.round(2)\n",
    "#print(d)\n",
    "\n",
    "#Variables \n",
    "index_list = dailySum.index #Index for updating df / Integear\n",
    "#print(type(index_list),index_list)\n",
    "#start_period = datetime.date.today() #Datetime object. Event Date of heavy rainfall\n",
    "#end_period = datetime.date.today()  #Datetime object. End of dry period after Event\n",
    "period_range = 0  #Amount of days after Event without much rain Integear\n",
    "period_amount = 0 #Amount of PP in dry days except event Integear\n",
    "event_amount = 0.0  #Amount of heavy rainfall on the event date Float\n",
    "#print(dailySum)\n",
    "#Conditions\n",
    "iteration = -1 #Iterations Steps\n",
    "duration = 0 #days\n",
    "duration_min_bevor = 4 #min dry days bevore survey start #necessary????\n",
    "duration_min_after = 10 #min dry days after survey\n",
    "pp = 0 #current pp\n",
    "pp_sum = 0.0 #mm\n",
    "pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "pp_max_1 = 0.11 #max pp for 1 day while counting dry days\n",
    "pp_max_2 = 0.5 #max pp for 1 week while counting dry days\n",
    "dry_days = 0 #dry days after event\n",
    "row = -1 #Panda rows\n",
    "count = False\n",
    "\n",
    "index_list = dailySum.index #Index for updating df / Integear\n",
    "period_range = 0  #Amount of days after Event without much rain Integear\n",
    "period_amount = 0 #Amount of PP in dry days except event Integear\n",
    "event_amount = 0.0  #Amount of heavy rainfall on the event date Float\n",
    "iteration = -1 #Iterations Steps\n",
    "duration = 0 #days\n",
    "duration_min_bevor = 4 #min dry days bevore survey start #necessary????\n",
    "duration_min_after = 10 #min dry days after survey\n",
    "pp = 0 #current pp\n",
    "pp_sum = 0.0 #mm\n",
    "pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "pp_max_1 = 0.11 #max pp for 1 day while counting dry days\n",
    "pp_max_2 = 0.5 #max pp for 1 week while counting dry days\n",
    "dry_days = 0 #dry days after event\n",
    "row = -1 #Panda rows\n",
    "count = False\n",
    "dry_periods = pd.DataFrame(columns=(\"start_period\",\"end_period\",\"period_range\",\"period_amount\",\"event_amount\",\"cell\"))\n",
    "dry_periods.start_period = dry_periods.start_period.astype('datetime64[ns]')\n",
    "dry_periods.end_period = dry_periods.end_period.astype('datetime64[ns]')\n",
    "columns = dailySum.columns\n",
    "numbers = range(len(columns))\n",
    "d = dict(zip(numbers,columns))\n",
    "         #dailySum1 = dailySum.iloc[0:0]\n",
    "for y in range(10):\n",
    "    for x in dailySum[columns[y]]:\n",
    "        iteration = iteration + 1\n",
    "        if x >= pp_min and count == False:\n",
    "            duration = duration + 1\n",
    "            count = True\n",
    "            row = row + 1\n",
    "            start_period = index_list[iteration]\n",
    "            event_amount = x\n",
    "            index = iteration\n",
    "            pp_sum = pp_sum + x\n",
    "            continue\n",
    "        elif x >= pp_min and count == True or x >= pp_max_1 and count == True:\n",
    "            end_period = index_list[iteration]\n",
    "            #new_entry = pd.DataFrame({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount} ,index=[1])\n",
    "            #dry_periods.update(new_entry)\n",
    "            dry_periods = dry_periods.append({\"start_period\":start_period ,\"end_period\":end_period,\"period_range\":duration,\"period_amount\":pp_sum ,\"event_amount\":event_amount, \"cell\":columns[y]},ignore_index=True).sort_values('period_range',ascending=False)\n",
    "            duration = 0\n",
    "            count = False\n",
    "            pp_sum = 0\n",
    "        elif pp <= pp_max_1 and count == True:\n",
    "            duration = duration + 1\n",
    "            pp_sum = pp_sum + x\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "print(dry_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "#Source\n",
    "df = dailySum\n",
    "\n",
    "#Conditions\n",
    "duration = 0 #days\n",
    "duration_min_bevor = 4 #min dry days bevore survey start #necessary????\n",
    "duration_min_after = 10 #min dry days after survey\n",
    "pp = 0 #current pp\n",
    "pp_sum = 0.0 #mm\n",
    "pp_min = 15.0 #mm min pp for start to count dry days until duration_min_after\n",
    "pp_max_1 = 0.1 #max pp for 1 day while counting dry days\n",
    "pp_max_2 = 0.5 #max pp for 1 week while counting dry days\n",
    "dry_days = 0 #dry days after event\n",
    "\n",
    "#Targets\n",
    "days = pd.DataFrame(columns=(\"event_date\",\"dry_days\",\"event_amount\",\"amount_dry_period\"))\n",
    "print(days.head())\n",
    "\n",
    "for x in df:\n",
    "    pp_sum = pp_sum + x[mm]\n",
    "    pp = x[mm]\n",
    "    print(\"actual:\", pp ,\"sum:\", pp_sum)\n",
    "    if pp_sum > pp_min:\n",
    "        duration = duration + 1\n",
    "        print(\"duration:\", duration)\n",
    "        if duration == duration_min_after:\n",
    "            event_date = df.date[x] - timedelta(days=duration_min_after)\n",
    "            event_amount = df.amount[x.index-10] \n",
    "            index = df.index[x]\n",
    "            print(\"event_date: \", event_date,\"event_amount: \",event_amount, \"index: ,\", index)\n",
    "            days = days.append([{\"event_date\":event_date,\"event_amount\":event_amount}], ignore_index=True) #date of event \n",
    "        elif duration > duration_min_after and pp <= pp_max_1:\n",
    "            dry_days = dry_days + 1\n",
    "        elif duration < duration_min_after:\n",
    "            continue\n",
    "        else:\n",
    "            df.set_value(index=index, col=\"dry_days\", value=dry_days, takeable=False)\n",
    "            days.iloc[index] = days\n",
    "            dry_days = 0\n",
    "            duration = 0\n",
    "            pp_sum = 0\n",
    "            continue\n",
    "    else:\n",
    "        continue \n",
    "                                 \n",
    "                                 \n",
    "print(days.head())                                 \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "                                 \n",
    "                                 \n",
    "                                 \n",
    "            \n",
    "#d = datetime.today() - timedelta(days=days_to_subtract)\n",
    "\n",
    "#res = pd.DataFrame(columns=('lib', 'qty1', 'qty2'))\n",
    "#res = res.append([{'qty1':10.0}], ignore_index=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
