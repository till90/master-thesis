{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master-Thesis \n",
    "\n",
    "Summary:  \n",
    "Find mysterious soil property corresponding to soil-moisture behaviours. First Idea is to look at soil-moisture content after a minimum of 10 mm precipitation occured. Analyse the drying behaviours of the soil in the dry period after the rain event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table-of-content  \n",
    "\n",
    "[AOI](#AOI)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modul imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2) # for printing pretty idk what it is... print with pp.pprint(print stuff)\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, GeoJSON, basemaps, Popup, LayersControl\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import Image, IFrame\n",
    "import ee\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "import altair as alt\n",
    "from sklearn import cluster\n",
    "from skimage import io, morphology, measure\n",
    "from osgeo import gdal, gdal_array\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TileLayerurl from ee to plot on ipyleaflet\n",
    "def GetTileLayerUrl(ee_image_object):\n",
    "    map_id = ee.Image(ee_image_object).getMapId()\n",
    "    tile_url_template = \"https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}\"\n",
    "    return tile_url_template.format(**map_id)\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOI\n",
    "\n",
    "The area of interest is the hessisches Ried. The shape is digitized from a screnshot taken from http://atlas.umwelt.hessen.de/servlet/Frame/atlas/naturschutz/naturraum/karten/m_3_2_1.htm . I found no better source. Info: The HLNUG is selling this shapes there's no open source map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AOI from GEE as FeatureCollection\n",
    "ried_225_222 = ee.FeatureCollection('users/tillmueller1990/ried_225_222') # Use this but the boundary isn't that precise at borders, got it from wms layer \n",
    "\n",
    "#Create Hessen AOI\n",
    "hesse_JSON = {\"type\":\"Polygon\",\"coordinates\":[[[9.4988,51.6315],[9.628,51.6373],[9.6407,51.6081],[9.689,51.5831],[9.6484,51.5495],[9.6128,51.5563],[9.6253,51.5344],[9.5904,51.5228],[9.6447,51.4723],[9.6277,51.4536],[9.6462,51.4208],[9.5717,51.3932],[9.5607,51.378],[9.5783,51.3711],[9.5555,51.363],[9.5618,51.3484],[9.7312,51.3008],[9.7655,51.3129],[9.7707,51.3425],[9.7361,51.3233],[9.7059,51.3705],[9.8013,51.3899],[9.7949,51.4082],[9.8194,51.4156],[9.8442,51.4047],[9.8508,51.3754],[9.8693,51.3754],[9.8562,51.4158],[9.9112,51.4198],[9.9366,51.394],[9.9249,51.3718],[9.9311,51.3421],[9.9492,51.3346],[9.9433,51.3086],[9.9734,51.301],[9.9735,51.2862],[10.0573,51.2783],[10.0516,51.256],[10.0756,51.2485],[10.0759,51.2262],[10.1415,51.2221],[10.1536,51.2072],[10.237,51.1881],[10.2078,51.1512],[10.2198,51.1437],[10.2142,51.1178],[10.1964,51.1142],[10.1722,51.1514],[10.1247,51.1406],[10.1785,51.118],[10.1492,51.0885],[10.1614,51.0699],[10.1497,51.0551],[10.1913,51.0512],[10.2213,51.0251],[10.1977,51.0215],[10.2096,51.014],[10.198,50.9992],[10.1565,50.9958],[10.1325,51.0107],[10.0429,51.0149],[10.0195,50.9817],[10.0436,50.9704],[10.0318,50.9631],[10.044,50.9482],[10.0679,50.948],[10.0143,50.9372],[9.9484,50.9484],[9.9487,50.9262],[9.9904,50.9372],[9.9668,50.915],[9.9789,50.9076],[10.0145,50.9223],[10.0629,50.885],[10.0214,50.8667],[10.0216,50.8519],[10.0395,50.8555],[10.022,50.8333],[9.9739,50.8372],[9.9502,50.8224],[9.9567,50.7817],[9.9267,50.7817],[9.9209,50.7632],[9.9389,50.7596],[9.939,50.7374],[9.9032,50.7079],[9.9151,50.6969],[9.8735,50.6747],[9.8731,50.6418],[9.9461,50.6301],[9.964,50.6448],[9.9455,50.6599],[9.9515,50.6709],[10.049,50.6773],[10.0861,50.6324],[10.0863,50.6212],[10.0619,50.6289],[10.0382,50.614],[10.0507,50.6025],[10.0451,50.5723],[10.063,50.5573],[10.0396,50.5347],[10.04,50.4933],[9.9646,50.4254],[9.8473,50.3983],[9.7993,50.4243],[9.7578,50.4241],[9.7304,50.3558],[9.7427,50.3447],[9.7386,50.2998],[9.6528,50.2693],[9.6367,50.2468],[9.6604,50.232],[9.5808,50.2201],[9.5001,50.2419],[9.5018,50.212],[9.5196,50.1972],[9.5029,50.1933],[9.5039,50.1746],[9.5325,50.1674],[9.5109,50.1485],[9.5194,50.0925],[9.4192,50.0803],[9.3773,50.1322],[9.2379,50.1493],[9.1999,50.1375],[9.2063,50.1228],[9.1695,50.0888],[9.1732,50.1185],[9.1384,50.1252],[9.0338,50.1121],[9.0171,50.0934],[8.9954,50.0451],[9.0481,50.0424],[9.049,50.0056],[9.0667,49.9948],[9.0319,49.9905],[9.0393,49.9096],[9.0632,49.8695],[9.0459,49.8655],[9.0576,49.8584],[9.0463,49.8472],[9.0752,49.8476],[9.0697,49.8328],[9.1041,49.8443],[9.0872,49.822],[9.105,49.7928],[9.1453,49.7969],[9.1171,49.7597],[9.1635,49.7454],[9.1295,49.7157],[9.1355,49.701],[9.0953,49.6933],[9.1135,49.6456],[9.0735,49.6232],[9.0739,49.6049],[9.1089,49.583],[9.0923,49.5461],[9.1333,49.5204],[9.1103,49.513],[9.1042,49.5315],[9.0694,49.535],[9.0469,49.5055],[8.9542,49.5121],[8.9546,49.4901],[8.9374,49.4826],[8.9552,49.4609],[8.9265,49.446],[8.9032,49.453],[8.8978,49.431],[8.8578,49.4049],[8.8404,49.4155],[8.8176,49.4041],[8.8002,49.4182],[8.8399,49.441],[8.8277,49.4771],[8.8621,49.4888],[8.8623,49.4742],[8.8796,49.4745],[8.9025,49.4894],[8.9021,49.5113],[8.8331,49.4991],[8.8267,49.5318],[8.7982,49.5166],[8.7291,49.522],[8.6818,49.5791],[8.7042,49.6017],[8.6868,49.6086],[8.6978,49.6272],[8.6004,49.6132],[8.595,49.5984],[8.6251,49.5517],[8.5915,49.525],[8.5572,49.5238],[8.469,49.5906],[8.429,49.5856],[8.3934,49.6176],[8.3619,49.6902],[8.4472,49.7224],[8.4861,49.7678],[8.4284,49.766],[8.3861,49.82],[8.3967,49.8499],[8.3493,49.8817],[8.3655,49.9192],[8.3468,49.9593],[8.2754,50.0165],[8.188,50.0325],[7.9868,49.975],[7.8877,49.9707],[7.8687,50.0082],[7.7851,50.0531],[7.7846,50.0681],[7.8131,50.087],[7.8483,50.0834],[7.8473,50.1097],[7.87,50.1286],[7.9411,50.1025],[7.9341,50.1326],[7.9456,50.1402],[7.8976,50.1699],[7.9196,50.2037],[8.0063,50.2346],[8.0479,50.2125],[8.0764,50.2317],[8.0406,50.2537],[8.0517,50.2688],[8.1278,50.2589],[8.1389,50.2741],[8.1254,50.3262],[8.0901,50.3331],[8.0828,50.3742],[7.9842,50.4136],[8.0072,50.429],[7.9942,50.4399],[8.03,50.4482],[7.9966,50.4847],[8.011,50.5261],[8.0565,50.5572],[8.1151,50.5358],[8.162,50.5513],[8.1736,50.6003],[8.1408,50.6117],[8.1588,50.6191],[8.1562,50.6342],[8.1187,50.6757],[8.1392,50.6989],[8.1531,50.6948],[8.1799,50.7358],[8.1319,50.7918],[8.1789,50.8068],[8.2757,50.8812],[8.2999,50.8812],[8.3203,50.8588],[8.3805,50.859],[8.419,50.9],[8.4715,50.9115],[8.468,50.9633],[8.5547,51.0132],[8.5355,51.039],[8.5175,51.0387],[8.5404,51.0578],[8.5152,51.076],[8.5382,51.0951],[8.6699,51.0903],[8.7346,51.1065],[8.7098,51.1321],[8.7678,51.1706],[8.7668,51.1968],[8.7844,51.2046],[8.7407,51.2485],[8.7522,51.26],[8.7094,51.2741],[8.6017,51.2458],[8.569,51.2751],[8.5744,51.2864],[8.6325,51.3361],[8.6694,51.3368],[8.7038,51.3749],[8.9576,51.3873],[8.9686,51.4285],[8.9387,51.4279],[8.9378,51.4578],[8.9125,51.4797],[8.9905,51.5073],[9.0419,51.5193],[9.06,51.5011],[9.1062,51.4982],[9.096,51.4609],[9.1139,51.4426],[9.1773,51.4438],[9.1996,51.4666],[9.2287,51.4597],[9.239,51.4896],[9.3188,51.5135],[9.3286,51.5544],[9.379,51.5924],[9.3435,51.6138],[9.435,51.6303],[9.4861,51.6571],[9.5037,51.6537],[9.4988,51.6315]]]}\n",
    "hessen_geometry = ee.Geometry.Polygon(hesse_JSON['coordinates'])\n",
    "\n",
    "# Rainfall Stations\n",
    "Alsfeld_Eifa = ee.Geometry.Point([9.3450,50.7446]) #Number 91 \n",
    "Aßlar_Klein_Altensteadten = ee.Geometry.Point([8.4685,50.5800]) #Number 211\n",
    "Biblis = ee.Geometry.Point([8.4179, 49.6896]) #Number 476\n",
    "stations = ee.FeatureCollection([Alsfeld_Eifa,Aßlar_Klein_Altensteadten,Biblis])\n",
    "stations_geometry = stations.geometry().getInfo()\n",
    "stations_geometry = ee.Geometry.MultiPoint(stations_geometry['coordinates'])\n",
    "stations_JSON = stations_geometry.toGeoJSON()\n",
    "\n",
    "#Get geometry and convert it to GeoJSON for visualisation purpose \n",
    "ried_geometry = ried_225_222.geometry().getInfo() #dict object\n",
    "ried_geometry = ee.Geometry.Polygon(ried_geometry['coordinates']) #cast to Geometry object\n",
    "ried_JSON = ried_geometry.toGeoJSON() #get GeoJSON object\n",
    "\n",
    "#get area of aoi\n",
    "ried_area = ried_225_222.geometry().area().getInfo()\n",
    "print(\"Hessisches Ried: Naturräumliche Einheiten 225 und 222, area: ca. \", ried_area/1000**2, \"km²\") #m² in km² \n",
    "\n",
    "#map properties\n",
    "center, zoom = (49.7252978589571, 8.34580993652344), 9\n",
    "\n",
    "#create basemap\n",
    "map_aoi = Map(center = center, zoom = zoom, basemap=basemaps.Esri.NatGeoWorldMap)\n",
    "\n",
    "#add Layer to map\n",
    "ried_viz = GeoJSON(data = ried_JSON, style = {'color': 'blue', 'opacity':1, 'fillOpacity':0.25}) #Create GeoJSON ipyleaflet object\n",
    "hesse_viz = GeoJSON(data = hesse_JSON, style = {'color': 'red', 'opacity':1, 'fillOpacity':0.25}) #Create GeoJSON ipyleaflet object\n",
    "stations_viz = GeoJSON(data = stations_JSON, style = {'color': 'blue'}) #Create GeoJSON ipyleaflet object\n",
    "\n",
    "map_aoi.add_layer(ried_viz) #add layer to map\n",
    "map_aoi.add_layer(hesse_viz) #add layer to map\n",
    "map_aoi.add_layer(stations_viz)\n",
    "\n",
    "#display map\n",
    "map_aoi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the radolan projection by compare precipitation data from rainfall measure stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load radolan test files\n",
    "I1 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090528').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "I2 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090529').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I3 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090530').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I4 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090531').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I5 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090601').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I6 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090602').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I7 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090603').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I8 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090604').reduceRegion(ee.Reducer.first(),Biblis).getInfo()\n",
    "I9 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090605').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "I10 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090606').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "I11 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090607').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "I12 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090608').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "I13 = ee.Image('users/tillmueller1990/radolan/dwd_radolan_09-19/090609').reduceRegion(ee.Reducer.mean(),Biblis).getInfo()\n",
    "\n",
    "#station data\n",
    "biblis_prep = [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19.0,0.4,9.3,0.2,0.4]\n",
    "biblis_radolan = [I1['b1'],I2['b1'],I3['b1'],I4['b1'],I5['b1'],I6['b1'],I7['b1'],I8['b1'],I9['b1'],I10['b1'],I11['b1'],I12['b1'],I13['b1']]\n",
    "print(biblis_prep)\n",
    "print(biblis_radolan)\n",
    "#[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 19.0, 0.4, 9.3, 0.2, 0.4]\n",
    "#0.0, 1.2999999523162842, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 5.699999809265137, 5.900000095367432, 2.700000047683716, 1.600000023841858]\n",
    "#[0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.700000000000001, 10.9, 1.6, 3.8000000000000003]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote sensed data\n",
    "\n",
    "This work try to obtain the most data from osm remotely sensed products or self derived data.  \n",
    "There are many properties affecting soil moisture:  \n",
    "1. Soil type  (X)\n",
    "2. Organic content  ( )\n",
    "3. Precipitation  (X)\n",
    "4. Vegetation  (X)\n",
    "5. Altitude  (X)\n",
    "6. Sun radiation (X)\n",
    "7. Cloudcover  ( )\n",
    "8. Soil temperature (X)\n",
    "9. Air temperature (X)\n",
    "10. Evaporation / Evapotranspiration (X)\n",
    "11. Wind relation (X)\n",
    "12. ? ( )\n",
    "\n",
    "A brief overview of available datasets:  \n",
    "\n",
    "### Earth Engine Datasets\n",
    "#### NASA-USDA Global Soil Moisture Data https://developers.google.com/earth-engine/datasets/catalog/NASA_USDA_HSL_soil_moisture\n",
    "revesit : 3days ; resoltion : 0.25 arc degrees (~25km)\n",
    "Surface soil moisture  \n",
    "Subsurface soil moisture  \n",
    "Soil moisture profile  \n",
    "Surface soil moisture anomaly  \n",
    "Subsurface soil moisture anomaly  \n",
    "#### CHIRPS Daily: Climate Hazards Group InfraRed Precipitation with Station Data https://developers.google.com/earth-engine/datasets/catalog/UCSB-CHG_CHIRPS_DAILY\n",
    "revesit : daily ; resolution : 0.05 arc degrees (~5km)  \n",
    "precipitation mm \n",
    "####  GLDAS-2.1: Global Land Data Assimilation System https://developers.google.com/earth-engine/datasets/catalog/NASA_GLDAS_V021_NOAH_G025_T3H\n",
    "revesit : 3 H , resolotion : 0.25 arc degrees (~25km)  \n",
    "Albedo  \n",
    "Average surface skin temperature  \n",
    "Plant canopy surface water  \n",
    "Canopy water evaporation  \n",
    "Direct evaporation from bare soil  \n",
    "Evapotranspiration  \n",
    "Downward long-wave radiation flux  \n",
    "Net long-wave radiation flux  \n",
    "Potential evaporation rate  \n",
    "Pressure \n",
    "Specific humidity  \n",
    "Heat flux  \n",
    "Sensible heat net flux  \n",
    "Latent heat net flux  \n",
    "Storm surface runoff  \n",
    "Baseflow-groundwater runoff  \n",
    "Snow melt  \n",
    "Total precipitation rat  \n",
    "Rain precipitation rate  \n",
    "Root zone soil moisture  \n",
    "Snow depth water equivalent  \n",
    "Downward short-wave radiation flux  \n",
    "Snow depth  \n",
    "Snow precipitation rate  \n",
    "Soil moisture  \n",
    "Soil temperature  \n",
    "Net short wave radiation flux  \n",
    "Air temperature  \n",
    "Transpiration  \n",
    "Wind speed  \n",
    "\n",
    "####  Corine Land Cover \n",
    "Year: 2012, resolution: 100m\n",
    "\n",
    "### Other Datasets\n",
    "\n",
    "#### Bodenübersichtskarte von Hessen http://bodenviewer.hessen.de/mapapps/resources/apps/bodenviewer/index.html?lang=de\n",
    "Year: 1997, scale: 1 : 500 000 bis zu 1:5000 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Type\n",
    "Soil type is important because different kind of soils have different potentials to release water at same weather conditions.   \n",
    "![Image of Yaktocat](http://www.soilmanagementindia.com/wp-content/uploads/2017/03/clip_image002-5.jpg)  \n",
    "\n",
    "I found no source for downloading a soil map in any format there are only wms layer and bodenviewer of HLNUG so i take a screenshot from HLNUG Bodenviewe.  \n",
    "The smallest scale fits on one screenshot. The other two scales (1:50.000 and 1:5.000) need several screenshots. Than you have to stich the images with e.g. autosticht together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='http://bodenviewer.hessen.de/mapapps/resources/apps/bodenviewer/index.html?lang=de&center=550000%2C5595000%2C25832&lod=3', width=1400, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Band Classifier (KMeans)\n",
    "Save this images as .tiff or .png to preserve the 3 bands. Because we need to make a KMeans classification and with more bands the classification is better. The number of possible soil classes are 32 + 1 for the white background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'C:\\Users\\USER\\Desktop\\master-thesis-master\\soil_map\\results\\great_hesse_soil_map_ref.tif'\n",
    "\n",
    "#Load file in gdal\n",
    "file = gdal.Open(filepath, gdal.GA_ReadOnly)\n",
    "\n",
    "#Initialize an array of zeros with size of input\n",
    "img = np.zeros((file.RasterYSize, file.RasterXSize, file.RasterCount), gdal_array.GDALTypeCodeToNumericTypeCode(file.GetRasterBand(1).DataType))\n",
    "\n",
    "#Loop over the number of bands in the image (img.shape[2]) insert values into the numpy array\n",
    "for b in range(img.shape[2]):\n",
    "    img[ : , : , b] = file.GetRasterBand(b + 1).ReadAsArray()\n",
    "\n",
    "#Reshape array \n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "\n",
    "#based on this shape, we can build the input value\n",
    "X = img[: , : , :3].reshape(new_shape)\n",
    "#X = np.where(X==150, 255, X) Bad idea because other r ,g or b values may have same as black and gray\n",
    "#X = np.where(X==0, 255, X) \n",
    "\n",
    "#Classifier Kmeans\n",
    "k_means = cluster.KMeans(n_clusters=33)\n",
    "k_means.fit(X)\n",
    "\n",
    "X_cluster = k_means.labels_\n",
    "X_cluster = X_cluster.reshape(img[:, :, 0].shape)\n",
    "\n",
    "#Get statistic values\n",
    "for i in np.unique(X_cluster):\n",
    "    blobs = np.int_(morphology.binary_opening(X_cluster == i))\n",
    "    color = np.around(k_means.cluster_centers_[i])\n",
    "    count = len(np.unique(measure.label(blobs))) - 1\n",
    "    print('Color: {}  >>  Objects: {}'.format(color, count))\n",
    "    \n",
    "#Plot the data\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(X_cluster)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Classification as GeoTiff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Open input image again to get properties\n",
    "file = gdal.Open(filepath)\n",
    "\n",
    "#We need a single band\n",
    "band = file.GetRasterBand(1)\n",
    "\n",
    "#Convert it to an array\n",
    "arr = band.ReadAsArray()\n",
    "\n",
    "#Extract columns and rows to a list\n",
    "[cols, rows] = arr.shape\n",
    "\n",
    "#Set the output as Geotiff\n",
    "format = \"GTiff\"\n",
    "driver = gdal.GetDriverByName(format)\n",
    "\n",
    "#Creates the output raster with the dimensions of the input raster\n",
    "#outDataRaster = driver.Create(\"soil_map_hesse_classify_33.tiff\", rows, cols, 1, gdal.GDT_Byte) -> activate this cell for saving image local\n",
    "\n",
    "#Set the projection and extent of the data.\n",
    "outDataRaster.SetGeoTransform(file.GetGeoTransform())##sets same geotransform as input\n",
    "outDataRaster.SetProjection(file.GetProjection())##sets same projection as input\n",
    "\n",
    "#Write classification result to a single band raster image \n",
    "outDataRaster.GetRasterBand(1).WriteArray(X_cluster)\n",
    "\n",
    "#Calling FlushCache() to remove from memory and delete the data\n",
    "outDataRaster.FlushCache() ## remove from memory\n",
    "del outDataRaster ## delete the data (not the actual geotiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Soil Types within Hessisches Ried\n",
    "\n",
    "Create Features for different soil types to compare soil-moisture. \n",
    "Die Patches müssen in 1km² große Patches unterteilt werden damit man den Niederschlagsfehler so klein wie möglich hält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Soil Types from BÜK 1:500.000 and clip to AOI\n",
    "BUK500_ried = ee.Image('users/tillmueller1990/soil_map_hesse_classify_33').clip(ried_225_222)\n",
    "\n",
    "#Correct raster values to corresponding soil class values # Some Values have same classes: raste Value 5 == 9+23, 0 == 8,33 Lösung: Bestimmte Patches durch eine Andere Farbe ersetzten?!\n",
    "raster_values = [0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31] \n",
    "viewer_values = [8,36,2,30,9,10,25,5,7,19,35,13,21,1,29,12,24,18,4,22,11,16,6,26,34,20,27,17,28,37,3]\n",
    "BUK500_ried = BUK500_ried.remap(raster_values, viewer_values).select(['remapped'],['b1']) # remap and rename bandNAme to previous name\n",
    "\n",
    "#Mask out Background // Not necessary if we use step above, then all values that are not listet get masked \n",
    "#mask = soil_map_great.neq(1) #Value 1 is invalid its the background (white) from screenshot or values with more than 1 soil class \n",
    "#soil_map_great = soil_map_great.updateMask(mask) #Apply Mask\n",
    "\n",
    "#Get Unique values to check if every value is signed correctly \n",
    "BUK500_ried_uniqueValues = BUK500_ried.reduceRegion(reducer=ee.Reducer.countDistinct(), geometry=ried_geometry, scale= 265 ,maxPixels= 1e10)\n",
    "print(\"BUK500_ried_uniqueValues\", BUK500_ried_uniqueValues.getInfo())\n",
    "\n",
    "#get area for each class\n",
    "class_areas_ried = ee.Image.pixelArea().divide(1000*1000).addBands(BUK500_ried).reduceRegion(reducer= ee.Reducer.sum().group(groupField= 1,groupName= 'Soil class'),geometry=ried_geometry,scale= 265, maxPixels= 1e10).get('groups') # sample the geometry at 1m intervals;\n",
    "#pp.pprint(class_areas.getInfo())\n",
    "\n",
    "#clip to clc landcover classes to avoid measuering over citys, forest or other dense vegetation\n",
    "soil_map_great_ried_clc = BUK500_ried.clip(clc_vector_ried)\n",
    "\n",
    "#Convert an image to a feature collection by reducing homogenous regions ->>>>> Hier nochmal nachschauen man muss die ganzen winzigen Features rausfiltern ....\n",
    "soil_map_great_ried_labeled = soil_map_great_ried_clc.connectedComponents(ee.Kernel.plus(255),250) #Finds connected components with the same value of the first band of the input and labels them with a globally unique value.\n",
    "soil_map_great_ried_scale = soil_map_great_ried_labeled.projection().nominalScale().getInfo() #get scale parameter \n",
    "features_ried_clc = soil_map_great_ried_labeled.reduceToVectors(reducer = ee.Reducer.first(), geometry= ried_geometry, scale= 265, geometryType= 'Polygon', eightConnected= False,maxPixels= 1e10) #FeatureCollection of patches\n",
    "\n",
    "def add_area_to_FC(feature):\n",
    "    return feature.set('area',  feature.geometry().area(1).divide(1000*1000))\n",
    "\n",
    "features_ried_clc = features_ried_clc.map(add_area_to_FC)\n",
    "pp.pprint(features_ried_clc.size().getInfo())\n",
    "\n",
    "#Grouped a count reducer: count number of land cover category pixels by patches\n",
    "count_ried = soil_map_great_ried_labeled.select(['labels','b1']).reduceRegion(reducer= ee.Reducer.count().group(groupField= 0, groupName= 'label'), geometry= ried_geometry, scale= 265,  maxPixels= 1e8)\n",
    "\n",
    "#Get test field for biggest area of soil class\n",
    "features_ried_clc = features_ried_clc.filterMetadata('area','greater_than',0.1)\n",
    "pp.pprint(features_ried_clc.size().getInfo())\n",
    "\n",
    "#Make random points for Features in Read\n",
    "random_ried = ee.FeatureCollection.randomPoints(features_ried_clc, 500)\n",
    "pp.pprint(random_ried.size().getInfo())\n",
    "\n",
    "#make sample polygon for ried with size of 1km²\n",
    "image_feature_ried = features_ried_clc.reduceToImage(['label'], ee.Reducer.first())\n",
    "#sample_regions_ried_clc_1km2 = image_feature_ried.reduceToVectors(ee.Reducer.first(), geometry, scale, geometryType, eightConnected, labelProperty, crs, crsTransform, bestEffort, maxPixels, tileScale, geometryInNativeProjection)\n",
    "\n",
    "#radolan polygons clipped to crop land over ried\n",
    "AOI_Features = ee.FeatureCollection('users/tillmueller1990/AOI_Features_clc_ried').filterBounds(ried_225_222)\n",
    "\n",
    "#Create LookUp Table for raster values corresponding to the soil type \n",
    "soil_types_legend = {1:'Niedermoore, Hochmoore', 2:'Vega, Auengleye, örtl. Anmoorgleye', 3:'Tschernoseme', 4:'Parabraunerden', 5:'Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden', 7:'Pararendzinen, Braunerden mit Bändern, örtl. Bänder-Parabraunerden', 8:'Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden', 9:'Pararendzinen', 13: 'Parabraunerden, örtl. Pseudogley-Parabraunerden',25: 'Braunerden, Ranker-Braunerden, Regosol-Braunerden' , 34 : 'Braunerden, Braunerde-Pseudogleye, örtl. Podsol-Braunerden'} #Legende\n",
    "raster_value_soil_value = {14:1, 3:2, 31:3, 19:4, 25:34, 7:25, 9:7 ,8:5, 9:7 , 0:8, 5:9 } # Value in raster value of legend\n",
    "\n",
    "soil_classes = ['Niedermoore, Hochmoore','Vega, Auengleye, örtl. Anmoorgleye','Tschernoseme','Parabraunerden','Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden','Lockerbraunerden','Pararendzinen, Braunerden mit Bändern, örtl. Bänder-Parabraunerden','Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden','Pararendzinen','Parabraunerden, Tschernoseme','Tschernosem-Parabraunerden, Parabraunerden, örtl. Pseudogley-Parabraunerden','Parabraunerden, örtl. Pseudogley-Parabraunerden und Tschernosem-Parabraunerden','Parabraunerden, örtl. Pseudogley-Parabraunerden','Parabraunerden und Pseudogleye','Pseudogley-Parabraunerden, Pseudogleye, Parabraunerden','Braunerden, Parabraunerden','Braunerden, örtl. Pseudogleye','Pseudogley-Parabraunerden, Pseudogleye, Braunerden','Pseudogley-Braunerden, Pseudogley-Parabraunerden, Pseudogleye','Pseudogleye mit Übergängen zu Stagnogleyen','Rendzinen','Rendzinen, Braunerden, Pelosole','Braunerden, Ranker-Braunerden, Regosol-Braunerden','Braunerden','Fersiallite, örtl. Ferralite','Braunerden, Pelosole, Rendzinen','Braunerden, Pelosole','Braunerden, Pseudogleye, vereinzelt Podsol-Braunerden','Braunerden, örtl. Podsol-Braunerden und Pseudogley-Braunerden','Braunerden, Braunerde-Pseudogleye, örtl. Podsol-Braunerden','Braunerden, Ranker-Braunerden, örtl. Braunerde-Podsole','Braunerde-Podsole, Podsole','Podsol-Braunerden, Pseudogley-Parabraunerden, örtl. Podsole']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export FeatureCollection to Earth Engine Assests\n",
    "#ee.batch.Export.table.toAsset(features_ried_clc, 'Connected features from Ried analyse','users/tillmueller1990/ried_features_connected').start()\n",
    "ee.batch.Export.table.toDrive(collection=features_ried_clc, fileFormat =\"SHP\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse SoilMoisture within fields of different soil types in Hesse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Soil Types from BÜK 1:500.000 and clip to AOI\n",
    "BUK500 = ee.Image('users/tillmueller1990/soil_map_hesse_classify_33')\n",
    "BUK500_test = ee.Image('users/tillmueller1990/soil_map_hesse_classify_33')\n",
    "\n",
    "#Correct raster values to corresponding soil class values # Some Values have same classes: raste Value 5 == 9+23, 0 == 8,33 Lösung: Bestimmte Patches durch eine Andere Farbe ersetzten?!\n",
    "raster_values = [2,3,4,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31] \n",
    "viewer_values = [36,2,30,10,25,5,7,19,35,13,21,1,29,12,24,18,4,22,11,16,6,26,34,20,27,17,28,37,3]\n",
    "print(len(raster_values),len(viewer_values))\n",
    "BUK500 = BUK500.remap(raster_values, viewer_values).select(['remapped'],['b1']) # remap and rename bandNAme to previous name\n",
    "\n",
    "#Mask out Background // Not necessary if we use step above, then all values that are not listet get masked \n",
    "#mask = soil_map_great.neq(1) #Value 1 is invalid its the background (white) from screenshot or values with more than 1 soil class \n",
    "#soil_map_great = soil_map_great.updateMask(mask) #Apply Mask\n",
    "\n",
    "#Get Unique values to check if every value is signed correctly \n",
    "BUK500_uniqueValues = BUK500.reduceRegion(reducer=ee.Reducer.countDistinct(), geometry=hessen_geometry, scale= 265 ,maxPixels= 1e10)\n",
    "print(\"BUK500_uniqueValues\", BUK500_uniqueValues.getInfo())\n",
    "\n",
    "#get area for each class\n",
    "class_areas = ee.Image.pixelArea().divide(1000*1000).addBands(BUK500).reduceRegion(reducer= ee.Reducer.sum().group(groupField= 1,groupName= 'Soil class'),geometry=hessen_geometry,scale= 265, maxPixels= 1e10).get('groups') # sample the geometry at 1m intervals;\n",
    "#pp.pprint(class_areas.getInfo())\n",
    "\n",
    "#clip to clc landcover classes to avoid measuering over citys, forest or other dense vegetation\n",
    "soil_map_great_clc = BUK500.clip(clc_vector_hesse)\n",
    "\n",
    "#Convert an image to a feature collection by reducing homogenous regions ->>>>> Hier nochmal nachschauen man muss die ganzen winzigen Features rausfiltern ....\n",
    "soil_map_great_labeled = soil_map_great_clc.connectedComponents(ee.Kernel.plus(255),250) #Finds connected components with the same value of the first band of the input and labels them with a globally unique value.\n",
    "soil_map_great_scale = soil_map_great_labeled.projection().nominalScale().getInfo() #get scale parameter \n",
    "features_clc = soil_map_great_labeled.reduceToVectors(reducer = ee.Reducer.first(), geometry= hessen_geometry, scale= 265, geometryType= 'Polygon', eightConnected= False,maxPixels= 1e10) #FeatureCollection of patches\n",
    "\n",
    "def add_area_to_FC(feature):\n",
    "    return feature.set('area',  feature.geometry().area(1).divide(1000*1000))\n",
    "#Feature Collection with Area attributes\n",
    "features_clc = features_clc.map(add_area_to_FC)\n",
    "\n",
    "#Grouped a count reducer: count number of land cover category pixels by patches\n",
    "count = soil_map_great_labeled.select(['labels','b1']).reduceRegion(reducer= ee.Reducer.count().group(groupField= 0, groupName= 'label'), geometry= hessen_geometry, scale= 265,  maxPixels= 1e8)\n",
    "\n",
    "#Get test field for biggest area of soil class\n",
    "features_clc = features_clc.filterMetadata('area','greater_than',0.1) #--> hier weiter machen zu viele patches \n",
    "pp.pprint(features_clc.size().getInfo())\n",
    "#pp.pprint(features_clc.getInfo())\n",
    "\n",
    "#Create LookUp Table for raster values corresponding to the soil type \n",
    "soil_types_legend = {1:'Niedermoore, Hochmoore', 2:'Vega, Auengleye, örtl. Anmoorgleye', 3:'Tschernoseme', 4:'Parabraunerden', 5:'Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden', 7:'Pararendzinen, Braunerden mit Bändern, örtl. Bänder-Parabraunerden', 8:'Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden', 9:'Pararendzinen', 13: 'Parabraunerden, örtl. Pseudogley-Parabraunerden',25: 'Braunerden, Ranker-Braunerden, Regosol-Braunerden' , 34 : 'Braunerden, Braunerde-Pseudogleye, örtl. Podsol-Braunerden'} #Legende\n",
    "raster_value_soil_value = {14:1, 3:2, 31:3, 19:4, 25:34, 7:25, 9:7 ,8:5, 9:7 , 0:8, 5:9 } # Value in raster value of legend\n",
    "\n",
    "soil_classes = ['Niedermoore, Hochmoore','Vega, Auengleye, örtl. Anmoorgleye','Tschernoseme','Parabraunerden','Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden','Lockerbraunerden','Pararendzinen, Braunerden mit Bändern, örtl. Bänder-Parabraunerden','Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden','Pararendzinen','Parabraunerden, Tschernoseme','Tschernosem-Parabraunerden, Parabraunerden, örtl. Pseudogley-Parabraunerden','Parabraunerden, örtl. Pseudogley-Parabraunerden und Tschernosem-Parabraunerden','Parabraunerden, örtl. Pseudogley-Parabraunerden','Parabraunerden und Pseudogleye','Pseudogley-Parabraunerden, Pseudogleye, Parabraunerden','Braunerden, Parabraunerden','Braunerden, örtl. Pseudogleye','Pseudogley-Parabraunerden, Pseudogleye, Braunerden','Pseudogley-Braunerden, Pseudogley-Parabraunerden, Pseudogleye','Pseudogleye mit Übergängen zu Stagnogleyen','Rendzinen','Rendzinen, Braunerden, Pelosole','Braunerden, Ranker-Braunerden, Regosol-Braunerden','Braunerden','Fersiallite, örtl. Ferralite','Braunerden, Pelosole, Rendzinen','Braunerden, Pelosole','Braunerden, Pseudogleye, vereinzelt Podsol-Braunerden','Braunerden, örtl. Podsol-Braunerden und Pseudogley-Braunerden','Braunerden, Braunerde-Pseudogleye, örtl. Podsol-Braunerden','Braunerden, Ranker-Braunerden, örtl. Braunerde-Podsole','Braunerde-Podsole, Podsole','Podsol-Braunerden, Pseudogley-Parabraunerden, örtl. Podsole']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create basemap\n",
    "map_s = Map(center = center, zoom = zoom, basemap=basemaps.Esri.NatGeoWorldMap)\n",
    "\n",
    "#soil color map\n",
    "soil_color_dict_ried = {1:'87FF4B', 2:'B5E6F5', 3:'D8A56D', 4:'C1994B', 5:'EDB74B', 7:'FFD1EE', 8:'FFE0A5', 9:'E99DFF',13:'FFBA43',25:'FFC3D1',34:'EECEA1'}\n",
    "soil_color_list_ried = list(soil_color_dict_ried.values())\n",
    "soil_color_dict = {1:'87FF4B', 2:'B5E6F5', 3:'D8A56D', 4:'C1994B', 5:'EDB74B', 6:'D579D1', 7:'FFD1EE', 10:'C1A771', 11:'D7AD98', 12:'DEA071', 13:'FFBA43', 16:'DBDB93', 17:'D9BE83', 18:'AC8A7B', 19:'CDA08C', 20:'E2CEAC', 21:'D7D1B1', 22:'DBDBDB', 24:'EED1FF', 25:'FFC3D1', 26:'FFD29D', 27:'FFA5A5', 28:'DB93B7', 29:'F7A1CB', 30:'E7BFA2', 34:'EECEA1', 35:'F7D86F', 36:'EDDD4B', 37:'FFE483'}\n",
    "soil_color_list = list(soil_color_dict.values())\n",
    "\n",
    "#add Layer to map\n",
    "soil_map_great_ried_viz = GetTileLayerUrl(BUK500_ried.visualize(min=0, max=10, palette=soil_color_list_ried)) #Create GeoJSON ipyleaflet object\n",
    "soil_map_great_ried_layer = ipyleaflet.TileLayer(url=soil_map_great_ried_viz,name='soil_map_great_ried')\n",
    "\n",
    "soil_map_great_ried_patches_viz = GetTileLayerUrl(features_ried_clc.draw(color='red').visualize())\n",
    "soil_map_great_ried_patches_layer = ipyleaflet.TileLayer(url=soil_map_great_ried_patches_viz, name='soil_class features_ried')\n",
    "\n",
    "soil_map_great_viz = GetTileLayerUrl(BUK500.visualize(min=0, max=29, palette=soil_color_list)) #Create GeoJSON ipyleaflet object\n",
    "soil_map_great_layer = ipyleaflet.TileLayer(url=soil_map_great_viz,name='soil_map_great')\n",
    "\n",
    "soil_map_great_patches_viz = GetTileLayerUrl(features_clc.draw(color='red').visualize())\n",
    "soil_map_great_patches_layer = ipyleaflet.TileLayer(url=soil_map_great_patches_viz, name='soil_class features')\n",
    "\n",
    "random_ried_viz = GetTileLayerUrl(random_ried.draw(color='blue').visualize())\n",
    "random_ried_layer = ipyleaflet.TileLayer(url=random_ried_viz, name='random points ried')\n",
    "\n",
    "image_feature_ried_viz = GetTileLayerUrl(image_feature_ried.visualize())\n",
    "image_feature_ried_layer = ipyleaflet.TileLayer(url=image_feature_ried_viz, name='image feature ried')\n",
    "\n",
    "AOI_Features_viz = GetTileLayerUrl(AOI_Features.draw(color='blue').visualize())\n",
    "AOI_Features_layer = ipyleaflet.TileLayer(url=AOI_Features_viz, name='AOI Features Ried')\n",
    "\n",
    "map_s.add_layer(soil_map_great_ried_layer) #add layer to map\n",
    "map_s.add_layer(soil_map_great_ried_patches_layer) #add layer to map\n",
    "map_s.add_layer(soil_map_great_layer) #add layer to map\n",
    "map_s.add_layer(soil_map_great_patches_layer) #add layer to map\n",
    "map_s.add_layer(random_ried_layer)\n",
    "map_s.add_layer(image_feature_ried_layer)\n",
    "map_s.add_layer(AOI_Features_layer)\n",
    "\n",
    "#display map\n",
    "map_s.add_control(LayersControl())\n",
    "map_s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Histogram\n",
    "def get_histogram_from_image(image,geometry):\n",
    "    dict_histogram = image.reduceRegion(reducer=ee.Reducer.autoHistogram(), geometry=geometry, scale= 265,maxPixels= 1e10).getInfo()['b1']\n",
    "    keys = [x[0] for x in dict_histogram if x[1] > 0.0]  #get keys from [key,value] list if value is > 0\n",
    "    values = [x[1] for x in dict_histogram if x[0] in keys] #get values for keys if the key is in value\n",
    "    return dict(zip(keys,values))\n",
    "\n",
    "histogram_soil_map_great_ried = get_histogram_from_image(BUK500_ried,ried_geometry)\n",
    "print(\"soil_map_great_ried_histogram\", histogram_soil_map_great_ried)\n",
    "\n",
    "plt.bar(histogram_soil_map_great_ried.keys(), histogram_soil_map_great_ried.values(), color='g')\n",
    "plt.title(\"Histogram soil class for ried\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_soil_map_great = get_histogram_from_image(BUK500,hessen_geometry)\n",
    "print(\"soil_map_great_histogram\", histogram_soil_map_great)\n",
    "\n",
    "plt.bar(histogram_soil_map_great.keys(), histogram_soil_map_great.values(), color='g')\n",
    "plt.title(\"Histogram soil class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil moisture from Sentinel 1 \n",
    "Here i try to derive soil moisture content from SAR data hostet on Google Earth Engine. The algorithm is a simple Change Detection Method more to this later...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentinel 1 backscatter raw data convertet to reflectivity range between 0 and 1 indicator for high reflectivity = high water volume content and vis verse \n",
    "#Load Sentinel 1 and filter data\n",
    "def load_dataset(ImageCollection_ID,begin,end,aoi):\n",
    "    ic = ee.ImageCollection(ImageCollection_ID).filterDate(begin,end).filterBounds(aoi)\n",
    "    return ic\n",
    "\n",
    "def filter_sentinel1(ImageCollection,polarisation,instrumentMode,resolution):\n",
    "    ic = ImageCollection.filter(ee.Filter.listContains('transmitterReceiverPolarisation',polarisation)).filter(ee.Filter.eq('instrumentMode',instrumentMode)).filterMetadata('resolution_meters','equals', resolution)\n",
    "    return ic\n",
    "\n",
    "def seperate_look_angels(ImageCollection):\n",
    "    Ascending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n",
    "    Descending = ImageCollection.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\n",
    "    return Ascending,Descending\n",
    "\n",
    "def seperate_tiles(ImageCollection,tiles):\n",
    "    tile_list = [x]\n",
    "\n",
    "def get_geometry(ImageCollection):\n",
    "    geometry = ImageCollection.geometry().getInfo()\n",
    "    #geometry = [x for x in geometry['coordinates']]\n",
    "    return geometry\n",
    "\n",
    "def show_tiles(ImageCollection):\n",
    "    geometry = get_geometry(ImageCollection)\n",
    "    geometry_list = list(geometry['coordinates'])\n",
    "    flattened_list = [y for x in geometry_list for y in x] #De flatter list \n",
    "    unique_list = []\n",
    "    unique_list = [x for x in flattened_list if x not in unique_list]\n",
    "    print(\"different tiles: \",len(unique_list))\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    geo_json = GeoJSON(data=geometry, style = {'color': 'green', 'opacity':1, 'weight':1.9, 'dashArray':'9', 'fillOpacity':0.1})\n",
    "    m.add_layer(geo_json)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "    \n",
    "def get_properties(ImageCollection):\n",
    "    features = ImageCollection.getInfo()['features']\n",
    "    dict_list = []\n",
    "    for f in features:\n",
    "        prop = f['properties']\n",
    "        dict_list.append(prop)\n",
    "    df = pd.DataFrame.from_records(dict_list).drop(['system:footprint','transmitterReceiverPolarisation'],axis=1)\n",
    "    #Pandas Series of unique distinc values in df\n",
    "    unique = df.nunique()\n",
    "    im_id_list = [item.get('id') for item in ImageCollection.getInfo().get('features')]\n",
    "    date_list = [datetime.datetime.strptime(x[35:43],'%Y%m%d') for x in im_id_list]\n",
    "    #property_names = list(df.columns.values) \n",
    "    return unique, im_id_list, date_list\n",
    "\n",
    "def make_mosaic(date,ImageCollection):\n",
    "    date = ee.Date(date['value'])\n",
    "    filterCollection = ImageCollection.filterDate(date, date.advance(1,'day'))\n",
    "    #Make the mosaic\n",
    "    image = ee.Image(filterCollection.mosaic()).copyProperties(filterCollection.first(),[\"system:time_start\"])\n",
    "    #Add the mosaic to a list only if the collection has images\n",
    "    #return ee.List(ee.Algorithms.If(filterCollection.size(), newList.add(image), newList))\n",
    "    return image\n",
    "\n",
    "def clip_aoi(ImageCollection):\n",
    "    im = ImageCollection.clip(ried_225_222)\n",
    "    return im\n",
    "\n",
    "def add_area(image):\n",
    "    area = image.multiply(ee.Image.pixelArea()).divide(-(1000*1000))\n",
    "    stat = area.reduceRegion(ee.Reducer.sum(),ried_225_222,10) \n",
    "    im = image.set('area',stat.get('VV'))\n",
    "    return im\n",
    "\n",
    "def reproject(image):\n",
    "    VV = image.select('VV')\n",
    "    return image.reporject({crs: VV.projection().crs(), scale : 100})\n",
    "\n",
    "def toNatural(image):\n",
    "    return ee.Image(10.0).pow(image.select(0).divide(10.0)).copyProperties(image)\n",
    "\n",
    "def toDB(image):\n",
    "    return ee.Image(image).log10().multiply(10.0).copyProperties(image)\n",
    "\n",
    "#Sigma Lee speckle filteringThe RL speckle filter from https://code.earthengine.google.com/2ef38463ebaf5ae133a478f173fd0ab5 by Guido Lemoine\n",
    "def RefinedLee(img):\n",
    "    #img must be in natural units, i.e. not in dB!\n",
    "    #Set up 3x3 kernels\n",
    "    weights3 = ee.List.repeat(ee.List.repeat(1,3),3)\n",
    "    kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False)\n",
    "    mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
    "    variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
    "    #Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "    sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]])\n",
    "    sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False)\n",
    "    #Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "    sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
    "    sample_var = variance3.neighborhoodToBands(sample_kernel)\n",
    "    #Determine the 4 gradients for the sampled windows\n",
    "    gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs()\n",
    "    gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
    "    #And find the maximum gradient amongst gradient bands\n",
    "    max_gradient = gradients.reduce(ee.Reducer.max())\n",
    "    #Create a mask for band pixels that are the maximum gradient\n",
    "    gradmask = gradients.eq(max_gradient)\n",
    "    #duplicate gradmask bands: each gradient represents 2 directions\n",
    "    gradmask = gradmask.addBands(gradmask)\n",
    "    #Determine the 8 directions\n",
    "    directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1)\n",
    "    directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2))\n",
    "    directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3))\n",
    "    directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4))\n",
    "    #The next 4 are the not() of the previous 4\n",
    "    directions = directions.addBands(directions.select(0).Not().multiply(5))\n",
    "    directions = directions.addBands(directions.select(1).Not().multiply(6))\n",
    "    directions = directions.addBands(directions.select(2).Not().multiply(7))\n",
    "    directions = directions.addBands(directions.select(3).Not().multiply(8))\n",
    "    #Mask all values that are not 1-8\n",
    "    directions = directions.updateMask(gradmask)\n",
    "    #\"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n",
    "    directions = directions.reduce(ee.Reducer.sum())\n",
    "    #Generate stats\n",
    "    sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
    "    #Calculate localNoiseVariance\n",
    "    sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0])\n",
    "    #Set up the 7*7 kernels for directional statistics\n",
    "    rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4))\n",
    "    #Set weights\n",
    "    diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0],[1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]])\n",
    "    rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False)\n",
    "    diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False)\n",
    "    #Create stacks for mean and variance using the original kernels Mask with relevant direction.\n",
    "    dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),diag_kernel).updateMask(directions.eq(2)))\n",
    "    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),diag_kernel).updateMask(directions.eq(2)))\n",
    "    #and add the bands for rotated kernels\n",
    "    for i in range(4):\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(),diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(),diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "    #\"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "    dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
    "    dir_var = dir_var.reduce(ee.Reducer.sum())\n",
    "    #A finally generate the filtered value\n",
    "    varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "    b = varX.divide(dir_var)\n",
    "    result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
    "    return result.arrayFlatten([['VV']]).copyProperties(img)\n",
    "\n",
    "def calc_asc_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_asc.select('VV_max'), 'omegaW' : minMax_asc.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def calc_des_soilMoisture(image):\n",
    "    im = image.expression('(omega - omegaD) / (omegaW - omegaD)', {'omega' : image.select('VV'), 'omegaD' : minMax_des.select('VV_max'), 'omegaW' : minMax_des.select('VV_min')})\n",
    "    return im.addBands(im).select(['VV','VV_1'],['Backscatter_Coefficient','soil_moisture_content'])\n",
    "\n",
    "def filter_IC(ImageCollection,filter):\n",
    "    old_size = ImageCollection.size().getInfo()\n",
    "    new_coll = ImageCollection.filter(filter)\n",
    "    new_size = new_coll.size().getInfo()\n",
    "    return new_coll\n",
    "\n",
    "def reducer(ImageCollection,reducer):\n",
    "    im = ImageCollection.reduce(reducer)\n",
    "    return im\n",
    "\n",
    "def plot_image(ImageCollection):\n",
    "    m = Map(center=(49.6252978589571, 8.34580993652344), zoom=7)\n",
    "    ic = GetTileLayerUrl(ImageCollection.first().visualize())\n",
    "    m.add_layer(ic)\n",
    "    dc = ipyleaflet.DrawControl()\n",
    "    m.add_control(dc)\n",
    "    m.add_control(LayersControl())\n",
    "    return m\n",
    "\n",
    "def windy_days_filter(image):\n",
    "    d = image.date().format('Y-M-d')\n",
    "    wx = ee.ImageCollection('NOAA/CFSV2/FOR6H')\n",
    "    vWind = wx.select(['v-component_of_wind_height_above_ground'])\n",
    "    a = vWind.max()\n",
    "    uWind = wx.select(['u-component_of_wind_height_above_ground'])\n",
    "    b = uWind.max()\n",
    "    a = a.pow(2)\n",
    "    b = b.pow(2)\n",
    "    ab = a.add(b)\n",
    "    ws = ab.sqrt()\n",
    "    ws = ws.multiply(3.6)\n",
    "    return image.updateMask(ws.lt(12))\n",
    "\n",
    "#Time of interest\n",
    "begin = ee.Date.fromYMD(2013,1,1)\n",
    "end = ee.Date.fromYMD(2019,6,1)\n",
    "date_range = end.difference(begin, 'day')\n",
    "\n",
    "#Source dataset\n",
    "sentinel1 = load_dataset('COPERNICUS/S1_GRD',begin,end,ried_225_222)\n",
    "print(\"sentinel1\",type(sentinel1),\"Collection Size: \", sentinel1.size().getInfo())\n",
    "\n",
    "#Filter dataset for High resolution and Vertical transmitt vertical receive\n",
    "sentinel1_VV = filter_sentinel1(sentinel1,'VV','IW',10)\n",
    "print(\"sentinel1_VV\",type(sentinel1_VV),\"Collection Size: \", sentinel1_VV.size().getInfo())\n",
    "\n",
    "print(sentinel1_VV.first().propertyNames().getInfo())\n",
    "#The RL speckle filter from https://code.earthengine.google.com/2ef38463ebaf5ae133a478f173fd0ab5 by Guido Lemoine\n",
    "sentinel1_VV_natural = sentinel1_VV.map(toNatural)\n",
    "#print(sentinel1_VV_natural.first().propertyNames().getInfo())\n",
    "sentinel1_VV_slFilter = sentinel1_VV_natural.map(RefinedLee)\n",
    "#print(sentinel1_VV_slFilter.first().propertyNames().getInfo())                      \n",
    "sentinel1_VV = sentinel1_VV_slFilter.map(toDB)\n",
    "#print(sentinel1_VV.first().bandNames().getInfo())\n",
    "#print(sentinel1_VV.first().propertyNames().getInfo())\n",
    "\n",
    "#Filter for different look angles\n",
    "VV_Ascending,VV_Descending = seperate_look_angels(sentinel1_VV)\n",
    "print(\"VV_Ascending\",type(VV_Ascending),\"VV_Descending\",type(VV_Descending),\"Collection Size: \", VV_Ascending.size().getInfo(), VV_Descending.size().getInfo())\n",
    "\n",
    "#Clip images to AOI and calculate area property\n",
    "VV_aoi_asc = VV_Ascending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_asc\",type(VV_aoi_asc),\"Collection Size: \", VV_aoi_asc.size().getInfo())\n",
    "VV_aoi_des = VV_Descending.map(clip_aoi).map(add_area)\n",
    "print(\"VV_aoi_des\",type(VV_aoi_des),\"Collection Size: \", VV_aoi_des.size().getInfo())\n",
    "\n",
    "#Create Min and Max bands for change detection method\n",
    "minMax_asc = reducer(VV_aoi_asc,ee.Reducer.minMax())\n",
    "print(\"minMax_asc\",type(minMax_asc),minMax_asc.getInfo())\n",
    "minMax_des = reducer(VV_aoi_des,ee.Reducer.minMax())\n",
    "print(\"minMax_des\",type(minMax_des),minMax_des.getInfo())\n",
    "\n",
    "#Compute soil moisture with simple change detection Methode\n",
    "VV_asc_sm = VV_aoi_asc.map(calc_asc_soilMoisture)\n",
    "print(\"VV_asc_sm\",type(VV_asc_sm),\"Collection Size: \", VV_asc_sm.size().getInfo())\n",
    "VV_des_sm = VV_aoi_des.map(calc_des_soilMoisture)\n",
    "print(\"VV_des_sm\",type(VV_des_sm),\"Collection Size: \", VV_des_sm.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get compareable test fields of soil classes\n",
    "Because it is not usefull to measure the sm content in areas of city, urban and forest we have to find bare or crop land or other spare vegetation land.  \n",
    "To find these areas there are two methods:  \n",
    "1. Is to detect these landclasses by a indice like ndvi, ndbi...., \n",
    "2. use existing data products like the corine land cover classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corine Land Cover (CLC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last corine land cover image \n",
    "clc = ee.Image.load('COPERNICUS/CORINE/V18_5_1/100m/2012', -1)\n",
    "\n",
    "# Mask areas where soil moisture measurements valid (farmland cat.:11-16)\n",
    "clc_mask = clc.gte(11).And(clc.lte(16)) #binary map for updateMask\n",
    "clc = clc.updateMask(clc_mask) #set mask for not Farmland\n",
    "\n",
    "# Clip to extend of Hessisches Ried\n",
    "clc_image_ried = clc.clip(ried_225_222) #image\n",
    "\n",
    "# Feature Collection of clc farmland cat.: 11-16 with 350m resolution\n",
    "clc_vector_ried = clc.reduceToVectors(geometry=ried_225_222, crs=clc.projection(), scale=100, geometryType='polygon', eightConnected = True) #FeatureCollection\n",
    "clc_vector_hesse = clc.reduceToVectors(geometry=hessen_geometry, crs=clc.projection(), scale=100, geometryType='polygon', eightConnected = True) #FeatureCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# Function to Convert Feature Classes to Pandas Dataframe\n",
    "# Adapted from: https://events.hpc.grnet.gr/event/47/material/1/12.py https://gis.stackexchange.com/questions/257727/iterate-over-imagecollection-returning-pandas-dataframe-using-earth-engine-pyt\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        ##attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        # attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = pd.DataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #print(df['geometry'])\n",
    "    #df['geometry'] = map(lambda s: shape(s), df.geometry)\n",
    "    #print(df['geometry'])\n",
    "    return df\n",
    "\n",
    "# ==========================================================================\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, features_aoi):\n",
    "    IC = data_set.filterMetadata('system:index', 'equals', img_id)\n",
    "    image = IC.reduce(ee.Reducer.mean())\n",
    "    fc_image_redR = image.reduceRegions(collection=features_aoi,\n",
    "                                  reducer = ee.Reducer.mean(),\n",
    "                                  scale = 1000,\n",
    "                                  crs = proj)\n",
    "\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_redR)\n",
    "\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(img_id[:],'%y%m%d')\n",
    "    return df_image_red\n",
    "\n",
    "# ==========================================================================\n",
    "#### Features\n",
    "features_f = AOI_Features\n",
    "\n",
    "#### Projection\n",
    "proj = ee.Projection('EPSG:4326')\n",
    "\n",
    "#### Load Raster\n",
    "data_set = radolan\n",
    "\n",
    "#### Make list of image IDs and Dates\n",
    "data_id = [item['properties']['system:index'] for item in data_set.getInfo().get('features')]\n",
    "data_date = [datetime.datetime.strptime(x[:],'%y%m%d') for x in data_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(data_id[0], features_f)\n",
    "df_all = df_all.drop([0,1])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in data_id:\n",
    "    df_all = df_all.append(extract_point_values(i, features_f))\n",
    "\n",
    "#save dataframe\n",
    "df_all.to_csv('radolan_1km2_AOI_Features.csv')\n",
    "\n",
    "#### Display Results\n",
    "df_all  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil Moisture ASC/DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SM ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# Function to Convert Feature Classes to Pandas Dataframe\n",
    "# Adapted from: https://events.hpc.grnet.gr/event/47/material/1/12.py https://gis.stackexchange.com/questions/257727/iterate-over-imagecollection-returning-pandas-dataframe-using-earth-engine-pyt\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        # attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #print(df['geometry'])\n",
    "    df['geometry'] = map(lambda s: shape(s), df.geometry)\n",
    "    #print(df['geometry'])\n",
    "    return df\n",
    "\n",
    "# ==========================================================================\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, features_aoi):\n",
    "    IC = data_set.filterMetadata('system:index', 'equals', img_id)\n",
    "    image = IC.reduce(ee.Reducer.mean())\n",
    "    fc_image_redR = image.reduceRegions(collection=features_aoi,\n",
    "                                  reducer = ee.Reducer.mean(),\n",
    "                                  scale = 1000,\n",
    "                                  crs = proj)\n",
    "\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_redR)\n",
    "\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(img_id[17:32],'%Y%m%dT%H%M%S')\n",
    "    return df_image_red\n",
    "\n",
    "# ==========================================================================\n",
    "#### Features\n",
    "features_f = AOI_Features\n",
    "\n",
    "#### Projection\n",
    "proj = ee.Projection('EPSG:4326')\n",
    "\n",
    "#### Load Raster\n",
    "data_set = VV_asc_sm.select('soil_moisture_content')\n",
    "\n",
    "#### Make list of image IDs and Dates\n",
    "data_id = [item['properties']['system:index'] for item in data_set.getInfo().get('features')]\n",
    "data_date = [datetime.datetime.strptime(x[17:32],'%Y%m%dT%H%M%S') for x in data_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(data_id[0], features_f)\n",
    "df_all = df_all.drop([0,1])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in data_id:\n",
    "    df_all = df_all.append(extract_point_values(i, features_f),sort=True)\n",
    "\n",
    "#save dataframe\n",
    "df_all.to_csv('sm_asc_1km2_AOI_Features.csv')\n",
    "\n",
    "#### Display Results\n",
    "df_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.iloc[231]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SM DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# Function to Convert Feature Classes to Pandas Dataframe\n",
    "# Adapted from: https://events.hpc.grnet.gr/event/47/material/1/12.py https://gis.stackexchange.com/questions/257727/iterate-over-imagecollection-returning-pandas-dataframe-using-earth-engine-pyt\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        # attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #print(df['geometry'])\n",
    "    df['geometry'] = map(lambda s: shape(s), df.geometry)\n",
    "    #print(df['geometry'])\n",
    "    return df\n",
    "\n",
    "# ==========================================================================\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, features_aoi):\n",
    "    IC = data_set.filterMetadata('system:index', 'equals', img_id)\n",
    "    image = IC.reduce(ee.Reducer.mean())\n",
    "    fc_image_redR = image.reduceRegions(collection=features_aoi,\n",
    "                                  reducer = ee.Reducer.mean(),\n",
    "                                  scale = 1000,\n",
    "                                  crs = proj)\n",
    "\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_redR)\n",
    "\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(img_id[17:32],'%Y%m%dT%H%M%S')\n",
    "    return df_image_red\n",
    "\n",
    "# ==========================================================================\n",
    "#### Features\n",
    "features_f = AOI_Features\n",
    "\n",
    "#### Projection\n",
    "proj = ee.Projection('EPSG:4326')\n",
    "\n",
    "#### Load Raster\n",
    "data_set = VV_des_sm.select('soil_moisture_content')\n",
    "\n",
    "#### Make list of image IDs and Dates\n",
    "data_id = [item['properties']['system:index'] for item in data_set.getInfo().get('features')]\n",
    "data_date = [datetime.datetime.strptime(x[17:32],'%Y%m%dT%H%M%S') for x in data_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(data_id[0], features_f)\n",
    "df_all = df_all.drop([0,1])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in data_id:\n",
    "    df_all = df_all.append(extract_point_values(i, features_f),sort=True)\n",
    "\n",
    "#save dataframe\n",
    "df_all.to_csv('sm_des_1km2_AOI_Features.csv')\n",
    "\n",
    "#### Display Results\n",
    "df_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# Function to Convert Feature Classes to Pandas Dataframe\n",
    "# Adapted from: https://events.hpc.grnet.gr/event/47/material/1/12.py https://gis.stackexchange.com/questions/257727/iterate-over-imagecollection-returning-pandas-dataframe-using-earth-engine-pyt\n",
    "def fc2df(fc):\n",
    "    # Convert a FeatureCollection into a pandas DataFrame\n",
    "    # Features is a list of dict with the output\n",
    "    features = fc.getInfo()['features']\n",
    "\n",
    "    dictarr = []\n",
    "\n",
    "    for f in features:\n",
    "        # Store all attributes in a dict\n",
    "        attr = f['properties']\n",
    "        # and treat geometry separately\n",
    "        attr['geometry'] = f['geometry']  # GeoJSON Feature!\n",
    "        # attr['geometrytype'] = f['geometry']['type']\n",
    "        dictarr.append(attr)\n",
    "\n",
    "    df = gpd.GeoDataFrame(dictarr)\n",
    "    # Convert GeoJSON features to shape\n",
    "    #print(df['geometry'])\n",
    "    df['geometry'] = map(lambda s: shape(s), df.geometry)\n",
    "    #print(df['geometry'])\n",
    "    return df\n",
    "\n",
    "# ==========================================================================\n",
    "# Function to iterate over image collection, returning a pandas dataframe\n",
    "def extract_point_values(img_id, pts):\n",
    "    IC = soil_moisture_1.filterMetadata('system:index', 'equals', img_id)\n",
    "    image = IC.reduce(ee.Reducer.mean())\n",
    "    fc_image_redR = image.reduceRegions(collection=pts,\n",
    "                                  reducer=ee.Reducer.mean(),\n",
    "                                  scale=1000,\n",
    "                                  crs = proj)\n",
    "\n",
    "    # Convert to Pandas Dataframe\n",
    "    df_image_red = fc2df(fc_image_redR)\n",
    "\n",
    "    # Add Date as Variable\n",
    "    df_image_red['date'] = datetime.datetime.strptime(img_id[:],'%y%m%d')\n",
    "    return df_image_red\n",
    "\n",
    "# ==========================================================================\n",
    "#### Features\n",
    "features_f = features_ried_clc\n",
    "\n",
    "#### Projection\n",
    "proj = ee.Projection('EPSG:4326')\n",
    "\n",
    "#### Load Raster\n",
    "soil_moisture_1 = radolan\n",
    "\n",
    "#### Make list of image IDs and Dates\n",
    "sm_1_id = [item['properties']['system:index'] for item in soil_moisture_1.getInfo().get('features')]\n",
    "sm_1_date = [datetime.datetime.strptime(x[:],'%y%m%d') for x in sm_1_id] #http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "\n",
    "#### Create Initial Pandas Dataframe\n",
    "df_all = extract_point_values(sm_1_id[0], features_f)\n",
    "df_all = df_all.drop([0,1])\n",
    "\n",
    "#### Iterate over all impages\n",
    "for i in sm_1_id:\n",
    "    df_all = df_all.append(extract_point_values(i, features_f))\n",
    "\n",
    "#### Display Results\n",
    "df_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe\n",
    "df_all.to_csv('radolan_1k_ried_clc.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation - RADOLAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radolan = ee.ImageCollection('users/tillmueller1990/radolan/dwd_radolan_09-19').filterDate(\"2014-1-1\",\"2019-05-31\")\n",
    "print(radolan.size().getInfo())\n",
    "print(radolan.first().bandNames().getInfo())\n",
    "print(radolan.first().date().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLDAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLDAS = ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n",
    "start,end = datetime.datetime(2014,1,1),datetime.datetime(2019,6,1)\n",
    "GLDAS = GLDAS.filterDate(start,end).filterMetadata('start_hour', 'equals', 18) #Daten für 18 Uhr if not than you have more than 5000 Elements\n",
    "print(GLDAS.first().get('system:index').getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "sm_asc = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\master_data\\GEE_data\\sm_s1_asc_250_ried_clc.csv\")\n",
    "sm_des = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\master_data\\GEE_data\\sm_s1_des_250_ried_clc.csv\")\n",
    "radolan = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\master_data\\GEE_data\\radolan_1k_ried_clc.csv\")\n",
    "gldas = pd.read_csv(r\"C:\\Users\\USER\\Desktop\\Masterarbeit\\DATA\\master_data\\GEE_data\\GLDAS_25k_ried_clc.csv\") \n",
    "\n",
    "#Delete invalid Geometry column\n",
    "soil_moisture_asc = sm_asc.drop(['area','label'], axis=1)\n",
    "soil_moisture_des = sm_des.drop(['geometry','area','label'], axis=1)\n",
    "precipitation = radolan.drop(['geometry','area','label'],axis=1)\n",
    "gldas_values = gldas.drop(['geometry','area','label'],axis=1)\n",
    "\n",
    "#rename column \n",
    "soil_moisture_asc.rename(columns={'Unnamed: 0':'Feature','first':'Soil class','mean':'sm_asc'}, inplace=True)\n",
    "soil_moisture_des.rename(columns={'Unnamed: 0':'Feature','first':'Soil class','mean':'sm_des'}, inplace=True)\n",
    "precipitation.rename(columns={'Unnamed: 0' : 'Feature', 'first' : 'Soil class','mean':'precipitation'}, inplace=True)\n",
    "#https://developers.google.com/earth-engine/datasets/catalog/NASA_GLDAS_V021_NOAH_G025_T3H ---> possible bands\n",
    "gldas_values.rename(columns={'Unnamed: 0' : 'Feature', 'first' : 'Soil class','Albedo_inst_mean':'Albedo',\n",
    "                           'AvgSurfT_inst_mean':'Average surface skin temperature','Evap_tavg_mean':'Evapotranspiration','ESoil_tavg_mean':'Direct evaporation from bare soil',\n",
    "                           'ECanop_tavg_mean':'Canopy water evaporation','Evap_tavg_mean':'Evapotranspiration',\"PotEvap_tavg_mean\":\"Potential evaporation rate\",\n",
    "                           }, inplace=True)\n",
    "\n",
    "#merge tabels\n",
    "model = precipitation\n",
    "#print(model.count,model.shape)\n",
    "model.insert(3,'sm_asc',soil_moisture_asc['sm_asc'],True)\n",
    "#print(model.count,model.shape)\n",
    "model.insert(4,'sm_des',soil_moisture_des['sm_des'],True)\n",
    "#print(model.count,model.shape)\n",
    "model.insert(5,'Potential evaporation rate',gldas_values['Potential evaporation rate'],True)\n",
    "#print(model.count,model.shape)\n",
    "\n",
    "# descriptions\n",
    "print(model.describe())\n",
    "\n",
    "\n",
    "\n",
    "#index dates\n",
    "#soil_moisture_asc.index = soil_moisture_asc['date']\n",
    "\n",
    "#gldas_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution\n",
    "#print(model.groupby('Feature').size())\n",
    "\n",
    "# box and whisker plots\n",
    "model.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
    "plt.show()\n",
    "\n",
    "# histograms\n",
    "model.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Datasets\n",
    "soil_moisture_asc = pd.read_csv(r'C:\\Users\\USER\\Desktop\\master-thesis-master\\sm_s1_des_250_ried_clc.csv') #Load from CSV file\n",
    "soil_moisture_asc = soil_moisture_asc.drop(['geometry'], axis=1) #Delete invalid Geometry column\n",
    "soil_moisture_asc.rename(columns={'Unnamed: 0':'Feature'}, inplace=True) #rename column \n",
    "soil_moisture_asc.rename(columns={'first':'Soil Class'}, inplace=True) #rename column \n",
    "soil_moisture_asc.index = soil_moisture_asc['date']\n",
    "del soil_moisture_asc['date']\n",
    "soil_moisture_asc_small = soil_moisture_asc[(soil_moisture_asc['Feature'] >= 1) & (soil_moisture_asc['Feature'] <=30 )]\n",
    "soil_moisture_asc_grouped = soil_moisture_asc.groupby('Soil Class')\n",
    "soil_moisture_asc_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radolan = ee.ImageCollection('users/tillmueller1990/radolan/radolan_dwd_germany')\n",
    "chirps  = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY').map(clip_aoi)\n",
    "soil_moisture_asc_ried_soil = chirps.toArray().reduceRegion(reducer=ee.Reducer.mean(), geometry=ried_geometry, scale=1000)\n",
    "soil_moisture_asc_ried_soil.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_attribute(obj, old_name, new_name):\n",
    "    obj.__dict__[new_name] = obj.__dict__.pop(old_name)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#Correct raster values to corresponding soil class values \n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(14),1) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(12),13) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(2),36) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(3),2) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(31),3) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(19),4) ##\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(25),34) ## \n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(7),25) ## FFC3D1,Braunerden, Ranker-Braunerden, Regosol-Braunerden\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(9),7) ## \n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(5),9) ## 5 = 9+23 \n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(8),5) ## \n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(0),8) ## 0=33(FFE0A5)(Braunerden, örtl. Podsol-Braunerden und Pseudogley-Braunerden) und 8 (Braunerden mit Bändern, Bänder-Parabraunerden, örtl. Podsol-Braunerden)\n",
    "soil_map_great = soil_map_great.where(soil_map_great.eq(8),5) ## \n",
    "\n",
    "\n",
    "#Raster,Viewer,Color,class,Ausgangsgestein 33\n",
    "2,36,EDDD4B,Podsol-Braunerden, Pseudogley-Parabraunerden, örtl. Podsole\n",
    "23,6,D579D1,Lockerbraunerden,Trachytische Aschen\n",
    "28,17,D9BE83,Pseudogley-Parabraunerden, Pseudogleye, Parabraunerden;Lösslehm mit Gesteinsbeimengungen\n",
    "20,22,DBDBDB,Pseudogleye mit Übergängen zu Stagnogleyen,Lösslehm über dichtem Untergrund\n",
    "13,21,D7D1B1,Pseudogley-Braunerden, Pseudogley-Parabraunerden, Pseudogleye,vorwiegend Lösslehm mit Gesteinsbeimengungen\n",
    "4,30,E7BFA2,Braunerden, Pseudogleye, vereinzelt Podsol-Braunerden,Tonschiefer, Grauwackenschiefer, Phyllit\n",
    "6,10,C1A771,Parabraunerden, Tschernoseme;Löss\n",
    "21,11,D7AD98,Tschernosem-Parabraunerden, Parabraunerden, örtl. Pseudogley-Parabraunerden;Löss\n",
    "16,12,DEA071,Parabraunerden, örtl. Pseudogley-Parabraunerden und Tschernosem-Parabraunerden;Löss\n",
    "22,16,DBDB93,Parabraunerden und Pseudogleye;Lösslehm, örtl. mit Gesteinsbeimengungen\n",
    "18,18,AC8A7B,Braunerden, Parabraunerden;Basalt, Lösslehm, Löss\n",
    "10,19,CDA08C,Braunerden, örtl. Pseudogleye;Basalt, Lösslehm\n",
    "26,20,E2CEAC,Pseudogley-Parabraunerden, Pseudogleye, Braunerden;Lösslehm, Basalt\n",
    "5,23,E89CFF,Rendzinen;Kalkstein, Mergel, Dolomit # == 5 but class 9 == val. 5\n",
    "17,24,EED1FF,Rendzinen, Braunerden, Pelosole;Kalkstein, Mergel, Dolomit, Ton- und Schluffsteine und Arkosen\n",
    "24,26,FFD29D,Braunerden;Schalstein, Diabas\n",
    "27,27,FFA5A5,Fersiallite, örtl. Ferralite;Basalt, Basalttuff\n",
    "29,28,DB93B7,Braunerden, Pelosole, Rendzinen;Ton- und Schluffsteine, Arkosen, Kalkstein, Mergel, Dolomit\n",
    "15,29,F7A1CB,Braunerden, Pelosole;Ton- und Schluffsteine und Arkosen, örtl. carbonathaltig\n",
    "0,33,FFE0A5,Braunerden, örtl. Podsol-Braunerden und Pseudogley-Braunerden;Schluff- und Tonsteine, Sandsteine\n",
    "11,35,F7D86F,Braunerden, Ranker-Braunerden, örtl. Braunerde-Podsole;Grauwacken, Sandsteine, Konglomerate, Quarzite, Kieselschiefer\n",
    "30,37,FFE483,Braunerde-Podsole, Podsole;Quarzite, Sandsteine\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
